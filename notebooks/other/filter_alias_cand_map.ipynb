{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import ujson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load alias map to filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading types from /dfs/scratch0/lorr1/projects/bootleg-data/embs/hyena_types_1229.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading /dfs/scratch0/lorr1/projects/bootleg-data/embs/hyena_types_1229.json: 100%|██████████| 5832699/5832699 [00:16<00:00, 344451.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading types from /dfs/scratch0/lorr1/projects/bootleg-data/embs/hyena_types_coarse_1229.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading /dfs/scratch0/lorr1/projects/bootleg-data/embs/hyena_types_coarse_1229.json: 100%|██████████| 5832699/5832699 [00:16<00:00, 349699.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from bootleg.symbols.type_symbols import TypeSymbols\n",
    "from bootleg.symbols.entity_symbols import EntitySymbols\n",
    "entity_dump = EntitySymbols(load_dir=\"/dfs/scratch0/lorr1/projects/bootleg-data/data/wiki_title_0122/entity_db/entity_mappings\")\n",
    "emb_dir = \"/dfs/scratch0/lorr1/projects/bootleg-data/embs\"\n",
    "types_hy = TypeSymbols(entity_dump, emb_dir, max_types=3, type_vocab_file=\"hyena_vocab.json\", type_file=\"hyena_types_1229.json\")\n",
    "types_coarse = TypeSymbols(entity_dump, emb_dir, max_types=3, type_vocab_file=\"hyena_coarse_vocab.json\", type_file=\"hyena_types_coarse_1229.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_aliases = entity_dump.get_alias2qids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load type mappings for adding back in countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load count files for all of wikipedia --- these were computed with `compute_statistics.py` (in utils/preprocessing) over the merged data file of test, dev, and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of times alias phrase occurs in the text across ALL of wikipedia\n",
    "alias_text_counts = ujson.load(\n",
    "    open('/dfs/scratch0/lorr1/projects/bootleg-data/data/all_wiki_title_0122/stats/alias_text_counts.json'))\n",
    "\n",
    "# number of times alias occurs as an alias across ALL of wikipedia\n",
    "alias_counts = ujson.load(\n",
    "    open('/dfs/scratch0/lorr1/projects/bootleg-data/data/all_wiki_title_0122/stats/alias_counts.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikidata types to keep\n",
    "regexes_of_types = [re.compile(p) for p in [\"^<wordnet_person_100007846>$\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple function to find aliases to remove based on the count files above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_value(alias, verbose=False):\n",
    "    if verbose:\n",
    "        print('# times occurs as alias:', alias_counts.get(alias, 0))\n",
    "        print('# times occurs in text:', alias_text_counts.get(alias, 0))\n",
    "    return alias_counts.get(alias, 0) / (alias_text_counts[alias]) if alias in alias_text_counts else -1\n",
    "\n",
    "def get_aliases_to_remove(curr_aliases, norm_threshold=0.017, min_seen=500, min_alias_count=10000):\n",
    "    \"\"\"\n",
    "    Remove aliases which are frequent words but infrequent aliases due to rarity \n",
    "    or mislabel (e.g. band \"themselves\").\n",
    "    \"\"\"\n",
    "    aliases_to_remove = set()\n",
    "    cnts = defaultdict(int)\n",
    "    grps = defaultdict(list)\n",
    "    for alias in tqdm(curr_aliases):\n",
    "        # If alias is not seen in Wikipedia\n",
    "        if alias not in alias_counts:\n",
    "            # If alias is seen in text but only a few times, skip as it's too few to make a decision\n",
    "            if (alias in alias_text_counts and alias_text_counts[alias] < min_seen):\n",
    "                continue\n",
    "            # if alias occurs in Wikidata (so it's in our alias map), but not as alias in Wikipedia\n",
    "            # and occurs more than min_seen times, only keep if one candidate (indicating a fairly unique alias)\n",
    "            # and if that one candidate is a type we care about (e.g., people and locations)\n",
    "            elif len(curr_aliases[alias]) == 1:\n",
    "                continue\n",
    "            # else make sure we don't think it's a person or location name - we want to keep those\n",
    "            # even if more general alias\n",
    "            else:\n",
    "                # just use the first QID and first type to see if person or location\n",
    "#                 qid = curr_aliases[alias][0][0]\n",
    "#                 typs = types_coarse.get_types(qid)\n",
    "#                 if len(typs) > 0 and any(r.search(typs[0]) for r in regexes_of_types):\n",
    "#                     grps[\"kept_person_wikidata\"].append(alias)\n",
    "#                     continue\n",
    "#                 else:\n",
    "                cnts[\"not_in_wikipedia\"] += 1\n",
    "                grps[\"not_in_wikipedia\"].append(alias)\n",
    "                aliases_to_remove.add(alias)\n",
    "                continue \n",
    "        # length greater than max_alias_len and weak labels cause some aliases to occur as aliases \n",
    "        # but not occur in the text\n",
    "        if alias not in alias_text_counts:\n",
    "            continue \n",
    "        # filter out aliases which occur commonly in the text but uncommonly as an alias\n",
    "        # we require that the alias is a common phrase in text \n",
    "        # and that the phrase isn't very commonly an alias \n",
    "        if (get_norm_value(alias) < norm_threshold):\n",
    "            if alias_text_counts[alias] > min_seen:\n",
    "                if alias_counts[alias] < min_alias_count:\n",
    "                    aliases_to_remove.add(alias)\n",
    "                    cnts[\"removed_filter\"] += 1\n",
    "                    grps[\"removed_filter\"].append(alias)\n",
    "                else:\n",
    "                    cnts[\"grt_min_alias_cnt\"] += 1\n",
    "                    grps[\"grt_min_alias_cnt\"].append(alias)\n",
    "            else:\n",
    "                cnts[\"lt_min_seen\"] += 1\n",
    "                grps[\"lt_min_seen\"].append(alias)\n",
    "    \n",
    "    return aliases_to_remove, cnts, grps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15290555/15290555 [00:20<00:00, 750835.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88058\n",
      "{\n",
      "    \"removed_filter\":50167,\n",
      "    \"grt_min_alias_cnt\":5,\n",
      "    \"lt_min_seen\":57584,\n",
      "    \"not_in_wikipedia\":37891\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aliases_to_remove, cnts, grps = get_aliases_to_remove(curr_aliases)\n",
    "print(len(aliases_to_remove))\n",
    "print(ujson.dumps(cnts, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checks on the filter step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "july 1918\n",
      "arthur gardiner\n",
      "shopper\n",
      "pleasant valley portland oregon\n",
      "race two\n",
      "multiple unit\n",
      "onboard\n",
      "たつのり\n",
      "you cant hurry love\n",
      "gowharan rural district hormozgan province\n",
      "her strange desire\n",
      "prophet s\n",
      "to hell\n",
      "snood anatomy\n",
      "the texas panhandler\n",
      "1963 film\n",
      "なかむら ゆり\n",
      "the american revolutionary war\n",
      "the orphans\n",
      "against new zealand\n",
      "womens synchronized trampoline\n",
      "jana gana mana film\n",
      "たかとみ\n",
      "drug stores\n",
      "saint patricks school\n",
      "guillotine choke\n",
      "list of linyphiidae species\n",
      "ibn abi talib\n",
      "lets turn back the years\n",
      "locksmith comics\n",
      "23\n",
      "aaron in islam\n",
      "canio\n",
      "6400\n",
      "マワタリ\n",
      "sanshiwu\n",
      "the time\n",
      "16thcentury\n",
      "pusillus\n",
      "singin\n",
      "5th battalion\n",
      "detonated\n",
      "sown\n",
      "arkansas house\n",
      "una vez mas leslie shaw song\n",
      "translate\n",
      "h2ac8\n",
      "may 1932\n",
      "duo onry ozzborn album\n",
      "duties\n"
     ]
    }
   ],
   "source": [
    "# sample what aliases are getting removed\n",
    "num_to_sample = 50\n",
    "for alias in np.random.choice(list(aliases_to_remove), num_to_sample): \n",
    "    print(alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for existence of certain words in aliases_to_remove\n",
    "sanity_checks = [('themselves', True), \n",
    "                 ('dolittle', False),\n",
    "                 ('us', False),\n",
    "                 ('s', True),\n",
    "                 ('is', True),\n",
    "                 ('also', True),\n",
    "                 ('in a world', True), \n",
    "                 ('of', True),\n",
    "                 ('the', True),\n",
    "                 ('by year', True),\n",
    "                 ('apoptosis', False),\n",
    "                 ('england', False)]\n",
    "for s, bool_val in sanity_checks: \n",
    "    assert (s in aliases_to_remove) is bool_val, f'{s} {bool_val} {s in aliases_to_remove}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WILL KEEP\n",
      "[['Q17', 72356], ['Q161652', 5851], ['Q5287', 5438], ['Q188712', 5093], ['Q184963', 4675], ['Q476215', 4653], ['Q219712', 3382], ['Q205662', 2752], ['Q1146127', 2364], ['Q170566', 2231], ['Q848647', 869], ['Q388232', 747], ['Q696251', 578], ['Q731647', 575], ['Q850204', 571], ['Q1122433', 562], ['Q234138', 498], ['Q179103', 457], ['Q831454', 408], ['Q575453', 368], ['Q130436', 359], ['Q962145', 346], ['Q736311', 340], ['Q231425', 287], ['Q603399', 271], ['Q210688', 258], ['Q533312', 249], ['Q3658577', 231], ['Q579842', 197], ['Q841337', 180]]\n",
      "['<yagoGeoEntity>']\n",
      "# times occurs as alias: 76417\n",
      "# times occurs in text: 558866\n",
      "NORM 0.1367358186041019\n"
     ]
    }
   ],
   "source": [
    "# debug the norm values to set different thresholds\n",
    "t = 'japan'\n",
    "if t in aliases_to_remove:\n",
    "    print(\"WILL REMOVE\")\n",
    "else:\n",
    "    print(\"WILL KEEP\")\n",
    "print(curr_aliases.get(t))\n",
    "print(types_coarse.get_types(curr_aliases[t][0][0]))\n",
    "print(f\"NORM\", get_norm_value(t, verbose=True))\n",
    "for k in grps:\n",
    "    if t in grps[k]:\n",
    "        print(k)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['princeps',\n",
       " 'timbaland thursday',\n",
       " '796',\n",
       " 'francaise',\n",
       " '615',\n",
       " '842',\n",
       " '19871988',\n",
       " 'notable works',\n",
       " '19861987',\n",
       " 'music directors',\n",
       " 'michel louis christophe roch gilbert motier marquis de la fayette',\n",
       " 'as well as',\n",
       " 'known in japan as',\n",
       " 'predecessor',\n",
       " 'alternatively',\n",
       " 'pharaohs daughter',\n",
       " 'caltex records releases',\n",
       " 'television and film',\n",
       " 'womens land army',\n",
       " 'governor of the state of rhode island and providence plantations',\n",
       " 'the cruel',\n",
       " 'the reformer',\n",
       " 'ov',\n",
       " '663',\n",
       " '569',\n",
       " 'kim jongkun',\n",
       " '13 wins',\n",
       " 'womens world championship',\n",
       " 'fut',\n",
       " 'previous club',\n",
       " 'cien',\n",
       " '22 goals',\n",
       " 'volodymyr tkachenko',\n",
       " 'juushirou',\n",
       " 'contributors',\n",
       " '477',\n",
       " '750',\n",
       " '594',\n",
       " 'womens prison',\n",
       " 'spotted',\n",
       " 'maksim lepskiy',\n",
       " 'sg wanna be',\n",
       " 'official caucus site',\n",
       " '100s50s',\n",
       " 'top score',\n",
       " 'best bowling',\n",
       " 'the bold',\n",
       " 'volume 5',\n",
       " '399',\n",
       " '362',\n",
       " 'pure opm classics',\n",
       " 'the paul',\n",
       " 'earl of calendar',\n",
       " 'earl of calender',\n",
       " 'general winstons daughter',\n",
       " 'television episodes',\n",
       " 'argent a lion rampant gules crowned or',\n",
       " 'similar to',\n",
       " '7 wins',\n",
       " '789',\n",
       " 'ladys maid',\n",
       " 'diavolo',\n",
       " 'sweeneys men',\n",
       " 'pacchionis granulations',\n",
       " 'as a director',\n",
       " 'williams jr',\n",
       " 'shams aldin',\n",
       " 'joudreville',\n",
       " 'saintpastour',\n",
       " 'as writer',\n",
       " 'as producer',\n",
       " 'minahan james',\n",
       " 'of nevers',\n",
       " 'original album',\n",
       " '19961997',\n",
       " '20022003',\n",
       " '20072008',\n",
       " 'hoffmanns drops',\n",
       " 'george edward',\n",
       " '2000 2004',\n",
       " 'sergei lysenko',\n",
       " 'nobodys angel',\n",
       " 'sergei nikolayev',\n",
       " 'kennedy jr',\n",
       " '5 february 1908 19 january 1929',\n",
       " 'the gallant',\n",
       " 'overland monthly and out west magazine volume 25',\n",
       " 'george h',\n",
       " '12 hours',\n",
       " 'archduchess maria luisa of austria princess of tuscany',\n",
       " 'with sean noonans brewed by noon',\n",
       " 'opponents',\n",
       " 'wanna be a bride',\n",
       " 'estelle caro eggleston',\n",
       " 'nasledje',\n",
       " 'franz xaver',\n",
       " 'the rooster',\n",
       " 'richard bland of jordans point',\n",
       " 'victoria adjo climbie',\n",
       " 'gioachino',\n",
       " 'xxpenive',\n",
       " 'bsg post rostock',\n",
       " 'and later',\n",
       " 'classics results timeline',\n",
       " 'devils walking stick',\n",
       " 'the bad',\n",
       " 'eugene v',\n",
       " 'except',\n",
       " '5 losses',\n",
       " 'im alright',\n",
       " 'film company',\n",
       " 'leupolz goals for germany',\n",
       " 'rumana islam kanak chapa',\n",
       " 'womens refuge',\n",
       " 'great one',\n",
       " 'of brabant',\n",
       " 'henry edward',\n",
       " 'appointed by',\n",
       " 'henriette knip',\n",
       " 'in french',\n",
       " 'the unfortunate',\n",
       " '542',\n",
       " '643',\n",
       " '531',\n",
       " 'usain',\n",
       " 'chris cantwell',\n",
       " 'lets play two',\n",
       " 'its alright between us as it is',\n",
       " 'daddys little girl',\n",
       " 'phusik',\n",
       " 'pusayk',\n",
       " 'pusices',\n",
       " 'pusik',\n",
       " 'the devils chaplain',\n",
       " 'notable work',\n",
       " 'took office',\n",
       " 'left office',\n",
       " 'legend to codiscoverers',\n",
       " 'kadm',\n",
       " 'as himself',\n",
       " 'brown jr',\n",
       " 'the mouse',\n",
       " 'giovanni francesco',\n",
       " '764',\n",
       " 'when the cats away',\n",
       " 'ndayi kalenga',\n",
       " 'francisco jose',\n",
       " '5 losses 0 draw 0 no contest',\n",
       " 'skeriks syncopated taint septet',\n",
       " 'other credits',\n",
       " 'director and writer',\n",
       " 'its not a dream',\n",
       " 'her majestys loyal opposition',\n",
       " 'john c',\n",
       " 'known in english as',\n",
       " 'opponent in final',\n",
       " 'opponents in final',\n",
       " 'dont blink',\n",
       " 'domhnall ua briain',\n",
       " 'aleksandr chernikov',\n",
       " 'thats me right there',\n",
       " 'labrege de la vie des peintresavec un traite du peintre parfait',\n",
       " 'the simple',\n",
       " '848',\n",
       " 'edward william',\n",
       " 'robert l',\n",
       " '656',\n",
       " 'comision de box y lucha df',\n",
       " 'official ky senate website',\n",
       " 'the fierce',\n",
       " 'the victorious',\n",
       " 'the peoples princess',\n",
       " 'often stylized as',\n",
       " 'chairman of the council of peoples commissars',\n",
       " 'the lame',\n",
       " 'totally',\n",
       " 'lilb',\n",
       " 'rhschomb',\n",
       " 'mrschomb',\n",
       " '684',\n",
       " 'creative team',\n",
       " 'sarahs law',\n",
       " 'guest musician',\n",
       " 'official pa senate website archived',\n",
       " 'official pa senate website',\n",
       " '647',\n",
       " '1097',\n",
       " 'tachr',\n",
       " 'tackh',\n",
       " 'asian japanese record',\n",
       " 'princesses of portugal',\n",
       " 'and now',\n",
       " 'li jiaxin',\n",
       " 'archies rival reggie',\n",
       " '070',\n",
       " 'igor kachmazov',\n",
       " 'the children of thomas j and anna r dorgan nee tobin',\n",
       " 'honored',\n",
       " 'qərarı',\n",
       " 'the migrant']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grps[\"kept_person_wikidata\"][:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove aliases and save new candidate mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15202497 VS 15290555\n"
     ]
    }
   ],
   "source": [
    "new_aliases = {}\n",
    "for alias in list(curr_aliases): \n",
    "    if alias not in aliases_to_remove:\n",
    "        new_aliases[alias] = curr_aliases[alias] \n",
    "print(len(new_aliases), \"VS\", len(curr_aliases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir = '/dfs/scratch0/lorr1/projects/bootleg-data/data/wiki_title_0122/entity_db/entity_mappings'\n",
    "# os.makedirs(new_dir, exist_ok=True)\n",
    "new_alias_file = f'{new_dir}/alias2qids_wiki_filt.json'\n",
    "\n",
    "with open(new_alias_file, 'w') as f: \n",
    "    ujson.save(new_aliases, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
