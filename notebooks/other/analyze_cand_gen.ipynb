{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computes the coverage of types and KG in terms of how filtering they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tutorials.utils import score_predictions\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import defaultdict, Counter\n",
    "import os,sys\n",
    "import ujson\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bootleg_emmental.utils.utils as utils\n",
    "from bootleg_emmental.symbols.type_symbols import TypeSymbols\n",
    "from bootleg_emmental.symbols.entity_symbols import EntitySymbols\n",
    "from bootleg_emmental.symbols.kg_symbols import KGSymbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading types from /dfs/scratch0/lorr1/projects/bootleg/embs/hyena_types_0905.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading /dfs/scratch0/lorr1/projects/bootleg/embs/hyena_types_0905.json: 100%|██████████| 5310039/5310039 [00:10<00:00, 513871.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading types from /dfs/scratch0/lorr1/projects/bootleg/embs/wikidata_types_0905.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading /dfs/scratch0/lorr1/projects/bootleg/embs/wikidata_types_0905.json: 100%|██████████| 5310039/5310039 [00:09<00:00, 544223.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading types from /dfs/scratch0/lorr1/projects/bootleg/embs/kg_relation_types_0905.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading /dfs/scratch0/lorr1/projects/bootleg/embs/kg_relation_types_0905.json: 100%|██████████| 5310039/5310039 [00:10<00:00, 506574.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading kg adj from /dfs/scratch0/lorr1/projects/bootleg/embs/kg_adj_0905.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25730507/25730507 [00:38<00:00, 666001.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# These are generated by Wikidata extractor\n",
    "input_dir = '/dfs/scratch0/lorr1/projects/bootleg/data/personal_model_1217_title/filtered_data'\n",
    "emb_dir = '/dfs/scratch0/lorr1/projects/bootleg/embs'\n",
    "qid2title = ujson.load(os.path.join(input_dir, \"entity_db/entity_mappings\"), \"qid2title.json\")\n",
    "entity_dump = EntitySymbols(load_dir=os.path.join(input_dir, \"entity_db/entity_mappings\"))\n",
    "types_hy = TypeSymbols(entity_dump, emb_dir, max_types=3, type_vocab_file=\"hyena_vocab.json\", type_file=\"hyena_types_0905.json\")\n",
    "types_wd = TypeSymbols(entity_dump, emb_dir, max_types=3, type_vocab_file=\"wikidata_to_typeid_0905.json\", type_file=\"wikidata_types_0905.json\")\n",
    "types_rel = TypeSymbols(entity_dump, emb_dir, max_types=50, type_vocab_file=\"relation_to_typeid_0905.json\", type_file=\"kg_relation_types_0905.json\")\n",
    "kg_syms = KGSymbols(entity_dump, emb_dir, \"kg_adj_0905.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_map_orig_f = os.path.join(input_dir, \"entity_db/entity_mappings/alias2qids.json\")\n",
    "cand_map_ctx_f = os.path.join(input_dir, \"contextual_candidates/entity_db/entity_mappings/alias2qids.json\")\n",
    "\n",
    "with open(cand_map_orig_f) as in_f:\n",
    "    cand_org = ujson.load(in_f)\n",
    "\n",
    "with open(cand_map_ctx_f) as in_f:\n",
    "    cand_ctx = ujson.load(in_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "qid_cnt = Counter()\n",
    "alias_by_qid_cnt = defaultdict(set)\n",
    "with open(os.path.join(input_dir, \"filtered_data\", \"train.jsonl\")) as in_f:\n",
    "    for line in in_f:\n",
    "        line = ujson.loads(line)\n",
    "        qid_cnt.update(line[\"qids\"])\n",
    "        train_data.append(line)\n",
    "\n",
    "with open(os.path.join(input_dir, \"filtered_data\", \"train.jsonl\")) as in_f:\n",
    "    for line in in_f:\n",
    "        line = ujson.loads(line)\n",
    "        for al, qid in zip(line['aliases'], line['qids']):\n",
    "            alias_by_qid_cnt[qid_cnt[qid]].add(al)\n",
    "        \n",
    "train_data_ctx = []\n",
    "with open(os.path.join(input_dir, \"contextual_candidates\", \"filtered_data\", \"train.jsonl\")) as in_f:\n",
    "    for line in in_f:\n",
    "        line = ujson.loads(line)\n",
    "        train_data_ctx.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig: 1962616\n",
      "Ctx: 4998995\n"
     ]
    }
   ],
   "source": [
    "print(f\"Orig: {len(cand_org)}\")\n",
    "print(f\"Ctx: {len(cand_ctx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_amb(cand_map):\n",
    "    d = defaultdict(list)\n",
    "    for al in tqdm(cand_map, desc=\"Computing type amb\"):\n",
    "        bad = 0\n",
    "        n = set()\n",
    "        for qid in cand_map[al]:\n",
    "            qid = qid[0]\n",
    "            not_already_counted = True\n",
    "            ty = types_wd.get_types(qid)\n",
    "            for t in ty:\n",
    "                if t not in n:\n",
    "                    n.add(t)\n",
    "                else:\n",
    "                    if not_already_counted:\n",
    "                        bad += 1\n",
    "                        not_already_counted = False\n",
    "        d[al] = [bad, len(cand_map[al])]\n",
    "    return d\n",
    "\n",
    "def compute_average_len(cand_map, min_qid_cnt=-1, max_qid_cnt=-1):\n",
    "    lengths = []\n",
    "    if min_qid_cnt == -1 and max_qid_cnt == -1:\n",
    "        for al in tqdm(cand_map, desc=\"Computing average len\"):\n",
    "            lengths.append(len(cand_map[al]))\n",
    "    else:\n",
    "        for cnt in tqdm(alias_by_qid_cnt, desc=\"Computing average len by count\"):\n",
    "            if min_qid_cnt <= cnt and (max_qid_cnt == -1 or cnt <= max_qid_cnt):\n",
    "                for al in alias_by_qid_cnt[cnt]:\n",
    "                    lengths.append(len(cand_map[al]))\n",
    "    print(f\"Mean: {np.mean(np.array(lengths))}, Max: {np.max(np.array(lengths))}, Min: {np.min(np.array(lengths))}, Median: {np.percentile(np.array(lengths), 50)}, 90th: {np.percentile(np.array(lengths), 90)}\")\n",
    "    return\n",
    "\n",
    "def compute_gold_overlap_kg(candidates, gold_qid):\n",
    "    gold_types = set(types_wd.get_types(gold_qid))\n",
    "    total_cands = len(candidates)\n",
    "    overlap = 0\n",
    "    for qid in candidates:\n",
    "        qid = qid[0]\n",
    "        ty = set(types_wd.get_types(qid))\n",
    "        if len(ty.intersection(gold_types)) > 0:\n",
    "            overlap += 1\n",
    "    return overlap, total_cands\n",
    "\n",
    "def compute_gold_overlap_type(candidates, gold_qid):\n",
    "    gold_types = set(types_wd.get_types(gold_qid))\n",
    "    total_cands = len(candidates)\n",
    "    overlap = 0\n",
    "    for qid in candidates:\n",
    "        qid = qid[0]\n",
    "        ty = set(types_wd.get_types(qid))\n",
    "        if len(ty.intersection(gold_types)) > 0:\n",
    "            overlap += 1\n",
    "    return overlap, total_cands\n",
    "\n",
    "def overlap_over_train(train_data, cand_map):\n",
    "    overlaps = []\n",
    "    total_cands_arr = []\n",
    "    for line in tqdm(train_data, desc=\"Iterating over train\"):\n",
    "        for al_idx, (al, qid) in enumerate(zip(line[\"aliases\"], line[\"qids\"])):\n",
    "            candidates = cand_map[al]\n",
    "            overlap, total_cands = compute_gold_overlap_type(candidates, qid)\n",
    "            if total_cands > 1:\n",
    "                overlaps.append(overlap/total_cands)\n",
    "                total_cands_arr.append(total_cands)\n",
    "    return overlaps, total_cands_arr\n",
    "\n",
    "\n",
    "def candidate_maps_comparison(train_data, train_data_other, cand_map, cand_map_other, n=10):\n",
    "    train_sent_to_data_other = {l[\"sent_idx_unq\"]: l for l in train_data_other}\n",
    "    i = 0\n",
    "    for line_orig in tqdm(train_data, desc=\"Iterating over train\"):\n",
    "        line_other = train_sent_to_data_other[line_orig[\"sent_idx_unq\"]]\n",
    "        if len(line_other[\"aliases\"]) != len(line_orig[\"aliases\"]):\n",
    "            print(\"LINE\", line_other, \"VS\", line_orig)\n",
    "            continue\n",
    "        if i >= n:\n",
    "            break\n",
    "        for qid_gold, al_orig, al_other in zip(line_orig[\"qids\"], line_orig[\"aliases\"], line_other[\"aliases\"]):\n",
    "            cands_orig = set(map(lambda x: x[0], cand_map[al_orig]))\n",
    "            cands_other = set(map(lambda x: x[0], cand_map_other[al_other]))\n",
    "            \n",
    "            intersec = len(cands_orig.intersection(cands_other))\n",
    "            print(line_orig[\"sentence\"])\n",
    "            print(f\"{qid_gold} {al_orig} {al_other} INTERSECTION: {intersec} ORIG LEN: {len(cands_orig)} OTHER LEN: {len(cands_other)}\")\n",
    "            \n",
    "            print(\"*********ORIG\")\n",
    "            for c in cands_orig:\n",
    "                print(entity_dump.get_title(c))\n",
    "              \n",
    "            print(\"********OTHER\")\n",
    "            for c in cands_other:\n",
    "                print(entity_dump.get_title(c))\n",
    "            \n",
    "            i += 1\n",
    "            if i >= n:\n",
    "                break\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing average len: 100%|██████████| 1962616/1962616 [00:01<00:00, 1396942.56it/s]\n",
      "Computing average len:   3%|▎         | 129496/4998995 [00:00<00:03, 1294955.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 1.3208116106258179, Max: 30, Median: 1.0, 90th: 1.0\n",
      "Average Length Orig None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing average len: 100%|██████████| 4998995/4998995 [00:04<00:00, 1089722.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 29.944735891914274, Max: 30, Median: 30.0, 90th: 30.0\n",
      "Average Length CTX None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Length Orig {compute_average_len(cand_org)}\")\n",
    "print(f\"Average Length CTX {compute_average_len(cand_ctx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing average len by count: 100%|██████████| 1002/1002 [00:00<00:00, 3617.18it/s]\n",
      "Computing average len by count:   3%|▎         | 28/1002 [00:00<00:04, 198.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 3.0202054336595148, Max: 30, Min: 1, Median: 1.0, 90th: 6.0\n",
      "Average Length Train Alias Orig None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing average len by count: 100%|██████████| 1002/1002 [00:00<00:00, 4662.66it/s]\n",
      "Computing average len by count: 100%|██████████| 1002/1002 [00:00<00:00, 299102.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 2.445066700962224, Max: 30, Min: 1, Median: 1.0, 90th: 4.0\n",
      "Average Tail Length Orig None\n",
      "Mean: 7.703167872287353, Max: 30, Min: 1, Median: 2.0, 90th: 30.0\n",
      "Average Tail Length Orig None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Length Train Alias Orig {compute_average_len(cand_org, min_qid_cnt=0, max_qid_cnt=-1)}\")\n",
    "print(f\"Average Tail Length Orig {compute_average_len(cand_org, min_qid_cnt=0, max_qid_cnt=11)}\")\n",
    "print(f\"Average Tail Length Orig {compute_average_len(cand_org, min_qid_cnt=1000, max_qid_cnt=5000)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = compute_amb(cand_org)\n",
    "r_ctx = compute_amb(cand_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Shared_Type Cands/Cands Orig 0.14403869780482964\n",
      "Avg Shared_Type Cands/Cands CTX 0.613427113665659\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg Shared_Type Cands/Cands Orig\", np.mean([p[0]/p[1] for p in r.values() if p[1] > 1]))\n",
    "print(\"Avg Shared_Type Cands/Cands CTX\", np.mean([p[0]/p[1] for p in r_ctx.values() if p[1] > 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating over train: 100%|██████████| 1306896/1306896 [00:56<00:00, 23038.44it/s]\n",
      "Iterating over train: 100%|██████████| 1306896/1306896 [02:29<00:00, 8748.51it/s] \n"
     ]
    }
   ],
   "source": [
    "r, r_cands = overlap_over_train(train_data, cand_org)\n",
    "r_ctx, r_cands_ctx = overlap_over_train(train_data_ctx, cand_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Gold Cand Overlap Orig 0.23272319718500287 16.802884243043923 2298350 1469461\n",
      "Avg Gold Cand Overlap Orig CTX 0.3391953839072476 29.961876128382148 3334420 433730\n"
     ]
    }
   ],
   "source": [
    "# Type overlap with gold QID over train (for num cands > 1)\n",
    "print(\"Avg Gold Cand Overlap Orig\", np.mean(np.array(r)), np.mean(np.array(r_cands)), len(r_cands), sum([o*total <= 1 for o, total in zip(np.array(r), np.array(r_cands))]))\n",
    "print(\"Avg Gold Cand Overlap Orig CTX\", np.mean(np.array(r_ctx)), np.mean(np.array(r_cands_ctx)), len(r_cands_ctx), sum([o*total <= 1 for o, total in zip(np.array(r_ctx), np.array(r_cands_ctx))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating over train:   0%|          | 7/1306896 [00:00<16:19:04, 22.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main monastery , housed in a building featuring stone floors , thick walls and high arched ceilings , is decorated with pictures of Pope John Paul II and Don Bosco .\n",
      "Q989 pope john paul ii al_109226_0_train INTERSECTION: 2 ORIG LEN: 3 OTHER LEN: 30\n",
      "*********ORIG\n",
      "Pope John Paul II\n",
      "Pope John Paul II (miniseries)\n",
      "Pope John Paul II (film)\n",
      "********OTHER\n",
      "John Fisher\n",
      "Pope John XXI\n",
      "John Lindsay\n",
      "Pope John XXII\n",
      "Pope John XII\n",
      "John II Komnenos\n",
      "Pope Urban II\n",
      "Beatification of Pope John Paul II\n",
      "Pope John Paul I\n",
      "Pope John Paul II (miniseries)\n",
      "Pope Paul II\n",
      "John Baldacci\n",
      "Pope John XXIII\n",
      "Pope Paul V\n",
      "John Paul Stevens\n",
      "Second Vatican Council\n",
      "Pope John Paul II\n",
      "John Taylor (bass guitarist)\n",
      "John F. Kennedy\n",
      "John II of France\n",
      "Pope Paul VI\n",
      "Pope Julius II\n",
      "Pope Callixtus II\n",
      "John Cody\n",
      "John and Paul\n",
      "Pope Honorius II\n",
      "John Cage\n",
      "John Pastore\n",
      "Paul John Hallinan\n",
      "Pope Gelasius II\n",
      "Lallu Bhaiya was an India n politician from the state of the Madhya Pradesh .\n",
      "Q668 india al_109227_0_train INTERSECTION: 13 ORIG LEN: 30 OTHER LEN: 30\n",
      "*********ORIG\n",
      "Indian Navy\n",
      "Presidencies and provinces of British India\n",
      "Census of India\n",
      "Partition of India\n",
      "Indian rupee\n",
      "Tamil Nadu\n",
      "Indian people\n",
      "Mughal Empire\n",
      "British Raj\n",
      "President of India\n",
      "Parliament of India\n",
      "Indian Space Research Organisation\n",
      "Indian Railways\n",
      "Constitution of India\n",
      "Indian subcontinent\n",
      "Demographics of India\n",
      "Indian independence movement\n",
      "India\n",
      "Indian Army\n",
      "Shah Jahan\n",
      "Cinema of India\n",
      "South India\n",
      "Indian Air Force\n",
      "Edward VII\n",
      "Queen Victoria\n",
      "India national cricket team\n",
      "Ayurveda\n",
      "Bollywood\n",
      "Government of India\n",
      "Prime Minister of India\n",
      "********OTHER\n",
      "Punjab, India\n",
      "Census of India\n",
      "Presidencies and provinces of British India\n",
      "Gujarat\n",
      "North India\n",
      "Telangana\n",
      "Indian rupee\n",
      "Communist Party of India\n",
      "Indian National Congress\n",
      "Indian people\n",
      "Tamil Nadu\n",
      "Assam\n",
      "British Raj\n",
      "President of India\n",
      "Maharashtra\n",
      "Goa\n",
      "Madhya Pradesh\n",
      "Constitution of India\n",
      "Odisha\n",
      "India\n",
      "Karnataka\n",
      "2011 Census of India\n",
      "Kerala\n",
      "Uttar Pradesh\n",
      "Cinema of India\n",
      "South India\n",
      "Andhra Pradesh\n",
      "India national cricket team\n",
      "East India\n",
      "Government of India\n",
      "Lallu Bhaiya was an India n politician from the state of the Madhya Pradesh .\n",
      "Q1188 madhya pradesh al_109227_1_train INTERSECTION: 4 ORIG LEN: 5 OTHER LEN: 30\n",
      "*********ORIG\n",
      "Madhya Pradesh women's cricket team\n",
      "Madhya Pradesh\n",
      "Madhya Pradesh cricket team\n",
      "Madhya Pradesh Legislative Assembly\n",
      "Government of Madhya Pradesh\n",
      "********OTHER\n",
      "Haryana\n",
      "Punjab, India\n",
      "Gujarat\n",
      "Telangana\n",
      "Himachal Pradesh\n",
      "Karnali Pradesh\n",
      "Bundelkhand\n",
      "Dewas district\n",
      "Maharashtra\n",
      "Chhattisgarh\n",
      "Madhya Pradesh\n",
      "Vindhya Pradesh\n",
      "Manipur\n",
      "Madhya Pradesh Legislative Assembly\n",
      "India\n",
      "Mizoram\n",
      "Rajasthan\n",
      "Moravia\n",
      "Dewas\n",
      "Uttar Pradesh\n",
      "Madhya Pradesh cricket team\n",
      "South India\n",
      "Andhra Pradesh\n",
      "Madhya Bharat\n",
      "Madhya Pradesh Stock Exchange\n",
      "Rohilkhand\n",
      "Madhya Pradesh football team\n",
      "Arunachal Pradesh\n",
      "Government of Madhya Pradesh\n",
      "Jharkhand\n",
      "Some scholars believe that this period of `` Paleolithic warlessness '' persisted until well after the appearance of `` Homo sapiens `` some 315,000 years ago , ending only at the occurrence of economic and social shifts associated with sedentism , when new conditions incentivized organized raiding of settlements .\n",
      "Q15978631 homo sapiens al_109228_0_train INTERSECTION: 4 ORIG LEN: 4 OTHER LEN: 30\n",
      "*********ORIG\n",
      "Homo sapiens\n",
      "Archaic humans\n",
      "Human\n",
      "European early modern humans\n",
      "********OTHER\n",
      "Capuchin monkey\n",
      "Homo\n",
      "Indian elephant\n",
      "Asian elephant\n",
      "Homo ergaster\n",
      "Adam and Eve\n",
      "Hippopotamus\n",
      "European early modern humans\n",
      "Haplogroup U (mtDNA)\n",
      "Wolf\n",
      "Primatology\n",
      "Homo sapiens\n",
      "Homo heidelbergensis\n",
      "Homo floresiensis\n",
      "Australopithecus sediba\n",
      "Convergent evolution\n",
      "Homo antecessor\n",
      "Haplogroup N-M231\n",
      "Archaic humans\n",
      "Australopithecus\n",
      "Pan (genus)\n",
      "Neanderthal\n",
      "Human\n",
      "Peking Man\n",
      "Pleistocene\n",
      "Hominidae\n",
      "Haplogroup H (mtDNA)\n",
      "Homo erectus\n",
      "Homo rhodesiensis\n",
      "Human taxonomy\n",
      "Despite the decline in demand for theatre and production art during the 1950s , McBean 's creative and striking ideas provided him with work in the emergent record cover business with companies such as EMI , when he was commissioned to create Cliff Richard 's first four album sleeves .\n",
      "Q183412 emi al_109232_2_train INTERSECTION: 3 ORIG LEN: 17 OTHER LEN: 30\n",
      "*********ORIG\n",
      "Emi Sakura\n",
      "Medium of instruction\n",
      "EMI Televisa Music\n",
      "EMI America Records\n",
      "Capitol Christian Music Group\n",
      "Capitol Latin\n",
      "EMI Records\n",
      "EMI Music Publishing\n",
      "Frank S. Emi\n",
      "EMI Films\n",
      "Emi Maria\n",
      "Emtithal Mahmoud\n",
      "EMI\n",
      "Emi Ferguson\n",
      "Emi Buendía\n",
      "European Movement International\n",
      "EMI Classics\n",
      "********OTHER\n",
      "British Phonographic Industry\n",
      "Virgin Records\n",
      "Angel Records\n",
      "Artists and repertoire\n",
      "Allianz\n",
      "EMI Classics\n",
      "A\n",
      "Warner Music Group\n",
      "Capitol Records\n",
      "Pye Records\n",
      "EMI Records\n",
      "HMV\n",
      "Virgin Group\n",
      "EMI\n",
      "Gramophone Company\n",
      "Ministry of Sound\n",
      "Apple Records\n",
      "Associated Independent Recording\n",
      "Prudential plc\n",
      "Stiff Records\n",
      "Royal Mail\n",
      "Plessey\n",
      "Avro\n",
      "Mercury Records\n",
      "Atlantic Records\n",
      "British Airways\n",
      "His Master's Voice\n",
      "Home Office\n",
      "Elektra Records\n",
      "Island Records\n",
      "Despite the decline in demand for theatre and production art during the 1950s , McBean 's creative and striking ideas provided him with work in the emergent record cover business with companies such as EMI , when he was commissioned to create Cliff Richard 's first four album sleeves .\n",
      "Q82238 cliff richard al_109232_4_train INTERSECTION: 1 ORIG LEN: 2 OTHER LEN: 30\n",
      "*********ORIG\n",
      "Cliff Richard\n",
      "Cliff Richard (1965 album)\n",
      "********OTHER\n",
      "Richard Marx\n",
      "Richard DeVos\n",
      "Richard II of England\n",
      "Richard Hawley\n",
      "Richard Nixon\n",
      "Richard Petty\n",
      "Richard III of England\n",
      "Richard Carpenter (musician)\n",
      "Bruce Springsteen\n",
      "Richard Niles\n",
      "Richard Hull\n",
      "Richard Vernon\n",
      "Richard Holloway\n",
      "Richard Barnes (author)\n",
      "Richard Helms\n",
      "Cliff Burton\n",
      "Richard Attenborough\n",
      "Richard Branson\n",
      "Richard Manuel\n",
      "Richard Burton\n",
      "Richard Ashcroft\n",
      "Richard Clapton\n",
      "Little Richard\n",
      "Richard Page (musician)\n",
      "Richard Rodney Bennett\n",
      "Cliff Richard\n",
      "Keith Richards\n",
      "Richard Thompson (musician)\n",
      "Richard Conrad\n",
      "Richard Chamberlain\n",
      "`` Drift '' , previously on loan to the Lighthouse Board and returned to the Survey for loan to the State of Virginia for oyster bed surveys during the summer of 1892 , was towed by the steamer `` Blake '' leaving on December 2 , 1892 from Norfolk , Virginia to the Washington Navy Yard where the `` Blake '' was to prepare for her trip to Chicago and the World 's Columbian Exposition .\n",
      "Q1637241 washington navy yard al_109233_0_train INTERSECTION: 1 ORIG LEN: 1 OTHER LEN: 30\n",
      "*********ORIG\n",
      "Washington Navy Yard\n",
      "********OTHER\n",
      "Mare Island Naval Shipyard\n",
      "Brooklyn Navy Yard\n",
      "Puget Sound Naval Shipyard\n",
      "Philadelphia Naval Shipyard\n",
      "Washington Naval Conference\n",
      "Boston Navy Yard\n",
      "Walter Reed National Military Medical Center\n",
      "Navy Yard (Washington, D.C.)\n",
      "Oriole Park at Camden Yards\n",
      "Naval Base San Diego\n",
      "Fort Lesley J. McNair\n",
      "Long Beach Naval Shipyard\n",
      "National Museum of the United States Navy\n",
      "Washington Navy Yard\n",
      "Federal Shipbuilding and Drydock Company\n",
      "United States Navy Memorial\n",
      "Hunters Point Naval Shipyard\n",
      "United States Navy\n",
      "Fort Washington Park\n",
      "United States Naval Academy\n",
      "The Pentagon\n",
      "Norfolk Naval Shipyard\n",
      "Charleston Naval Shipyard\n",
      "Washington National Cathedral\n",
      "Lake Washington Shipyard\n",
      "Naval Weapons Station Yorktown\n",
      "Portsmouth Naval Shipyard\n",
      "Washington, D.C.\n",
      "Kaiser Shipyards\n",
      "Washington Naval Treaty\n",
      "`` Drift '' , previously on loan to the Lighthouse Board and returned to the Survey for loan to the State of Virginia for oyster bed surveys during the summer of 1892 , was towed by the steamer `` Blake '' leaving on December 2 , 1892 from Norfolk , Virginia to the Washington Navy Yard where the `` Blake '' was to prepare for her trip to Chicago and the World 's Columbian Exposition .\n",
      "Q285406 world s columbian exposition al_109233_1_train INTERSECTION: 1 ORIG LEN: 1 OTHER LEN: 30\n",
      "*********ORIG\n",
      "World's Columbian Exposition\n",
      "********OTHER\n",
      "Exposition Universelle (1878)\n",
      "Pan American Games\n",
      "1896 United States presidential election\n",
      "Exposition Universelle (1889)\n",
      "Lewis and Clark Centennial Exposition\n",
      "1912 Summer Olympics\n",
      "1896 Summer Olympics\n",
      "Pan-American Exposition\n",
      "Centennial Exposition\n",
      "1964 New York World's Fair\n",
      "1888 Barcelona Universal Exposition\n",
      "Exposition Universelle (1900)\n",
      "William McKinley\n",
      "1998 FIFA World Cup\n",
      "2002 FIFA World Cup\n",
      "1994 FIFA World Cup\n",
      "Trans-Mississippi Exposition\n",
      "Century 21 Exposition\n",
      "World's fair\n",
      "World's Columbian Exposition\n",
      "Louisiana Purchase Exposition\n",
      "1862 International Exhibition\n",
      "California Midwinter International Exposition of 1894\n",
      "Sesquicentennial Exposition\n",
      "McCormick Place\n",
      "Manifest destiny\n",
      "Great Exhibition\n",
      "South by Southwest\n",
      "2014 FIFA World Cup\n",
      "Century of Progress\n",
      "Alaska , separated from the contiguous United States by Canada , is the largest state at .\n",
      "Q797 alaska al_109234_0_train INTERSECTION: 3 ORIG LEN: 30 OTHER LEN: 30\n",
      "*********ORIG\n",
      "2014 Alaska gubernatorial election\n",
      "List of United States senators from Alaska\n",
      "Alaska Thunderfuck\n",
      "Paleontology in Alaska\n",
      "Herman of Alaska\n",
      "Alaska (novel)\n",
      "2000 United States presidential election in Alaska\n",
      "Alaska!\n",
      "Alaska\n",
      "Alaska Range\n",
      "Carl J. Lomen\n",
      "Innocent of Alaska\n",
      "Alaska (singer)\n",
      "District of Alaska\n",
      "Alaska Statehood Act\n",
      "University of Alaska Fairbanks\n",
      "Alaska Airlines\n",
      "Alaska Milk Corporation\n",
      "Alaska Nanooks men's ice hockey\n",
      "Roman Catholic Diocese of Fairbanks\n",
      "Alaska Natives\n",
      "Alaska Aces (PBA)\n",
      "Alaska Highway\n",
      "Territory of Alaska\n",
      "History of Alaska\n",
      "Russian America\n",
      "Galena, Alaska\n",
      "Alaska Legislature\n",
      "Alaska P. Davidson\n",
      "Alaska Aces (ECHL)\n",
      "********OTHER\n",
      "Virginia\n",
      "U.S. state\n",
      "Maine\n",
      "Wyoming\n",
      "Fairbanks, Alaska\n",
      "Contiguous United States\n",
      "Alaska\n",
      "Juneau, Alaska\n",
      "Federated States of Micronesia\n",
      "Matanuska-Susitna Borough, Alaska\n",
      "Sonora\n",
      "Kazakhstan\n",
      "Oklahoma\n",
      "Idaho\n",
      "Kansas\n",
      "Arizona\n",
      "Hawaii\n",
      "Minnesota\n",
      "Aleutian Islands\n",
      "Sitka, Alaska\n",
      "Alaska Natives\n",
      "Territory of Alaska\n",
      "Anchorage, Alaska\n",
      "Utqiagvik, Alaska\n",
      "Washington (state)\n",
      "Oregon\n",
      "Palau\n",
      "Southeast Alaska\n",
      "Alaska's at-large congressional district\n",
      "Utah\n",
      "The series was based on the Pulitzer Prize winning book , `` Profiles in Courage `` by US President John F Kennedy , who had been assassinated the year before .\n",
      "Q46525 pulitzer prize al_109235_0_train INTERSECTION: 7 ORIG LEN: 16 OTHER LEN: 30\n",
      "*********ORIG\n",
      "Pulitzer Prize for History\n",
      "Pulitzer Prize for Feature Photography\n",
      "Pulitzer Prize\n",
      "Pulitzer Prize for Biography or Autobiography\n",
      "Pulitzer Prize for Photography\n",
      "Pulitzer Prize for Commentary\n",
      "Pulitzer Prize for National Reporting\n",
      "Pulitzer Prize for Public Service\n",
      "Pulitzer Prize for Criticism\n",
      "Pulitzer Prize for Drama\n",
      "1951 Pulitzer Prize\n",
      "2000 Pulitzer Prize\n",
      "Pulitzer Prize for Poetry\n",
      "Pulitzer Prize for Music\n",
      "Pulitzer Prize for Editorial Cartooning\n",
      "Pulitzer Prize for Fiction\n",
      "********OTHER\n",
      "Pulitzer Prize for History\n",
      "National Book Award\n",
      "Pulitzer Prize\n",
      "National Book Critics Circle Award\n",
      "Bancroft Prize\n",
      "Academy Awards\n",
      "World Series\n",
      "Nobel Prize\n",
      "Eisner Award\n",
      "Hugo Award\n",
      "Eclipse Award\n",
      "Nobel Memorial Prize in Economic Sciences\n",
      "Heisman Trophy\n",
      "Pulitzer Prize for Investigative Reporting\n",
      "Newbery Medal\n",
      "Academy Award for Best Adapted Screenplay\n",
      "Grammy Award\n",
      "Pulitzer Prize for Biography or Autobiography\n",
      "Associated Press\n",
      "Pulitzer Prize for Public Service\n",
      "Pulitzer Prize for Drama\n",
      "Pulitzer Prize for General Nonfiction\n",
      "Pulitzer Prize for Poetry\n",
      "Pulitzer Prize for Fiction\n",
      "Booker Prize\n",
      "America's Cup\n",
      "Pulitzer Prize for Feature Writing\n",
      "Maria Moors Cabot Prizes\n",
      "Nobel Prize in Literature\n",
      "Supreme Court of the United States\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "candidate_maps_comparison(train_data, train_data_ctx, cand_org, cand_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qid2cnt = defaultdict(int)\n",
    "with open(os.path.join(input_dir, \"train.jsonl\")) as in_f:\n",
    "    for line in in_f:\n",
    "        line = ujson.loads(line)\n",
    "        for qid in line[\"qids\"]:\n",
    "            qid2cnt[qid] += 1\n",
    "qid2cnt = dict(qid2cnt)\n",
    "with open(os.path.join(input_dir, \"train_qidcnt.json\"), \"w\") as out_f:\n",
    "    ujson.save(qid2cnt, out_f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(os.path.join(input_dir, \"train_qidcnt.json\"), \"r\") as in_f:\n",
    "    qid2cnt = ujson.load(in_f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fill in the prediction file generated from mode dump_preds\n",
    "pred_file = '/dfs/scratch0/lorr1/data/bootleg/bootleg-internal/runs/ablations_0929/kg_only/20200929_043739/merged_dump2/eval/model1/bootleg_labels.jsonl'\n",
    "\n",
    "kg_df = score_predictions(orig_file=f'{input_dir}/test.jsonl',\n",
    "                 pred_file=pred_file,\n",
    "                 title_map=qid2title,\n",
    "                 cands_map=cand_org,\n",
    "                 type_symbols=[types_hy, types_wd, types_rel],\n",
    "                 kg_symbols=[kg_syms])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}