{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this before going through candidate generation to augment the base data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /lfs/1/simran/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import nltk \n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import ast\n",
    "import json\n",
    "import ujson\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68124, 14)\n",
      "(22631, 14)\n",
      "(15509, 14)\n"
     ]
    }
   ],
   "source": [
    "base_data = '/dfs/scratch1/simran/tacred/tacred-relation-bootleg/dataset_bootleg_iclr_model/tacred/base_data'\n",
    "\n",
    "train_file = \"{}/train.json\".format(base_data)\n",
    "with open(train_file) as train:\n",
    "    df_train = json.load(train)\n",
    "    df_train = pd.DataFrame.from_dict(df_train, orient='columns')\n",
    "    print(df_train.shape)\n",
    "    \n",
    "dev_file = \"{}/dev_rev.json\".format(base_data)\n",
    "with open(dev_file) as dev:\n",
    "    df_dev = json.load(dev)\n",
    "    df_dev = pd.DataFrame.from_dict(df_dev, orient='columns')\n",
    "    print(df_dev.shape)\n",
    "    \n",
    "test_file = \"{}/test_rev.json\".format(base_data)\n",
    "with open(test_file) as test:\n",
    "    df_test = json.load(test)\n",
    "    df_test = pd.DataFrame.from_dict(df_test, orient='columns')\n",
    "    print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'docid', 'relation', 'token', 'subj_start', 'subj_end',\n",
      "       'obj_start', 'obj_end', 'subj_type', 'obj_type', 'stanford_pos',\n",
      "       'stanford_ner', 'stanford_head', 'stanford_deprel'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# augment pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_row(row):\n",
    "    tokens = row['token']\n",
    "    ss, se = row['subj_start'], row['subj_end']\n",
    "    os, oe = row['obj_start'], row['obj_end']\n",
    "    subj = ' '.join(tokens[ss:se+1])\n",
    "    obj = ' '.join(tokens[os:os+1])\n",
    "    print(\"TOKENS: \", tokens)\n",
    "    print(\"SUBJ: \", subj)\n",
    "    print(\"OBJ: \", obj)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['-LSB-', 'By', 'the', 'way', ',', 'I', 'first', 'pointed', 'out', 'Alice', 'when', 'she', 'was', 'announced', 'as', 'being', 'the', 'new', 'Agent', 'Provocateur', 'face', ',', 'since', 'then', 'they', \"'ve\", 'been', 'giving', 'her', 'a', 'MASSIVE', 'PR', 'push', '-LRB-', 'obviously', 'got', 'big', 'plans', 'for', 'her', '-RRB-', ',', 'in', 'The', 'Sun', 'in', 'particular', ',', 'which', 'I', 'missed', '.']\n",
      "ner_tags: ['O', 'O', 'O', 'O', 'O', 'O', 'ORDINAL', 'O', 'O', 'PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'MISC', 'MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "subj: ['Alice']\n",
      "obj: ['she']\n",
      "tokens: ['-LSB-', 'By', 'the', 'way', ',', 'I', 'first', 'pointed', 'out', 'Alice', 'when', 'Alice', 'announced', 'as', 'being', 'the', 'new', 'Agent', 'Provocateur', 'face', ',', 'since', 'then', 'they', \"'ve\", 'been', 'giving', 'her', 'a', 'MASSIVE', 'PR', 'push', '-LRB-', 'obviously', 'got', 'big', 'plans', 'for', 'her', '-RRB-', ',', 'in', 'The', 'Sun', 'in', 'particular', ',', 'which', 'I', 'missed', '.']\n",
      "ner_tags: ['O', 'O', 'O', 'O', 'O', 'O', 'ORDINAL', 'O', 'O', 'PERSON', 'O', 'P', 'E', 'R', 'S', 'O', 'N', 'O', 'O', 'O', 'O', 'O', 'MISC', 'MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "subj: ['Alice', 'when']\n",
      "obj: ['Alice', 'announced', 'as']\n",
      "Split: train\n",
      "Of the examples with pronouns,  1  have just 1 person ner tag in them.\n",
      "Of these examples pronouns, replaced 0  subj as a pronoun\n",
      "Of these examples pronouns, replaced 1  obj as a pronoun\n",
      "\n",
      "tokens: ['After', 'several', 'years', 'spent', 'largely', 'at', 'the', 'Centre', 'National', 'de', 'la', 'Recherche', 'Scientifique', 'in', 'Paris', ',', 'Mandelbrot', 'was', 'hired', 'by', 'IBM', 'in', '1958', 'to', 'work', 'at', 'the', 'Thomas', 'J.', 'Watson', 'Research', 'Center', 'in', 'Yorktown', 'Heights', ',', 'N.Y.', 'Although', 'he', 'worked', 'frequently', 'with', 'academic', 'researchers', 'and', 'served', 'as', 'a', 'visiting', 'professor', 'at', 'Harvard', 'and', 'the', 'Massachusetts', 'Institute', 'of', 'Technology', ',', 'it', 'was', 'not', 'until', '1987', 'that', 'he', 'began', 'to', 'teach', 'at', 'Yale', ',', 'where', 'he', 'earned', 'tenure', 'in', '1999', '.']\n",
      "ner_tags: ['O', 'DURATION', 'DURATION', 'O', 'O', 'O', 'O', 'ORGANIZATION', 'ORGANIZATION', 'ORGANIZATION', 'ORGANIZATION', 'ORGANIZATION', 'ORGANIZATION', 'O', 'LOCATION', 'O', 'PERSON', 'O', 'O', 'O', 'ORGANIZATION', 'O', 'DATE', 'O', 'O', 'O', 'O', 'ORGANIZATION', 'ORGANIZATION', 'ORGANIZATION', 'ORGANIZATION', 'ORGANIZATION', 'O', 'LOCATION', 'LOCATION', 'O', 'LOCATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'ORGANIZATION', 'O', 'O', 'ORGANIZATION', 'ORGANIZATION', 'ORGANIZATION', 'ORGANIZATION', 'O', 'O', 'O', 'O', 'O', 'DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'ORGANIZATION', 'O', 'O', 'O', 'O', 'O', 'O', 'DATE', 'O']\n",
      "subj: ['he']\n",
      "obj: ['1987']\n",
      "tokens: ['After', 'several', 'years', 'spent', 'largely', 'at', 'the', 'Centre', 'National', 'de', 'la', 'Recherche', 'Scientifique', 'in', 'Paris', ',', 'Mandelbrot', 'was', 'hired', 'by', 'IBM', 'in', '1958', 'to', 'work', 'at', 'the', 'Thomas', 'J.', 'Watson', 'Research', 'Center', 'in', 'Yorktown', 'Heights', ',', 'N.Y.', 'Although', 'he', 'worked', 'frequently', 'with', 'academic', 'researchers', 'and', 'served', 'as', 'a', 'visiting', 'professor', 'at', 'Harvard', 'and', 'the', 'Massachusetts', 'Institute', 'of', 'Technology', ',', 'it', 'was', 'not', 'until', '1987', 'that', 'Mandelbrot', 'to', 'teach', 'at', 'Yale', ',', 'where', 'he', 'earned', 'tenure', 'in', '1999', '.']\n",
      "ner_tags: ['O', 'DURATION', 'DURATION', 'O', 'O', 'O', 'O', 'ORGANIZATION', 'ORGANIZATION', 'ORGANIZATION', 'ORGANIZATION', 'ORGANIZATION', 'ORGANIZATION', 'O', 'LOCATION', 'O', 'PERSON', 'O', 'O', 'O', 'ORGANIZATION', 'O', 'DATE', 'O', 'O', 'O', 'O', 'ORGANIZATION', 'ORGANIZATION', 'ORGANIZATION', 'ORGANIZATION', 'ORGANIZATION', 'O', 'LOCATION', 'LOCATION', 'O', 'LOCATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'ORGANIZATION', 'O', 'O', 'ORGANIZATION', 'ORGANIZATION', 'ORGANIZATION', 'ORGANIZATION', 'O', 'O', 'O', 'O', 'O', 'DATE', 'O', 'P', 'E', 'R', 'S', 'O', 'N', 'O', 'O', 'O', 'ORGANIZATION', 'O', 'O', 'O', 'O', 'O', 'O', 'DATE', 'O']\n",
      "subj: ['Mandelbrot', 'to', 'teach']\n",
      "obj: ['1987', 'that']\n",
      "Split: dev\n",
      "Of the examples with pronouns,  1  have just 1 person ner tag in them.\n",
      "Of these examples pronouns, replaced 1  subj as a pronoun\n",
      "Of these examples pronouns, replaced 0  obj as a pronoun\n",
      "\n",
      "tokens: ['Salaam', ',', 'represented', 'by', 'Kunstler', 'at', 'sentencing', 'and', 'in', 'his', 'unsuccessful', 'appeals', ',', 'got', 'a', 'seven-year', 'term', '.']\n",
      "ner_tags: ['O', 'O', 'O', 'O', 'PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DURATION', 'O', 'O']\n",
      "subj: ['his']\n",
      "obj: ['seven-year']\n",
      "tokens: ['Salaam', ',', 'represented', 'by', 'Kunstler', 'at', 'sentencing', 'and', 'in', 'Kunstler', 'appeals', ',', 'got', 'a', 'seven-year', 'term', '.']\n",
      "ner_tags: ['O', 'O', 'O', 'O', 'PERSON', 'O', 'O', 'O', 'O', 'P', 'E', 'R', 'S', 'O', 'N', 'O', 'O', 'O', 'O', 'DURATION', 'O', 'O']\n",
      "subj: ['Kunstler', 'appeals', ',']\n",
      "obj: ['term', '.']\n",
      "Split: test\n",
      "Of the examples with pronouns,  1  have just 1 person ner tag in them.\n",
      "Of these examples pronouns, replaced 1  subj as a pronoun\n",
      "Of these examples pronouns, replaced 0  obj as a pronoun\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# length\n",
    "pronouns = ['he', 'she', 'her', 'his', 'him']\n",
    "length = 1\n",
    "df_list = [df_train, df_dev, df_test]\n",
    "df_names = ['train', 'dev', 'test']\n",
    "for i in range(len(df_list)):\n",
    "    df = df_list[i]\n",
    "    num_one_person_var = 0\n",
    "    subj_pronoun = 0\n",
    "    obj_pronoun = 0\n",
    "    for index, row in df.iterrows(): \n",
    "        tokens = row['token']\n",
    "        ss, se = row['subj_start'], row['subj_end']\n",
    "        os, oe = row['obj_start'], row['obj_end']\n",
    "        subj = ' '.join(tokens[ss:se+1])\n",
    "        obj = ' '.join(tokens[os:os+1])\n",
    "        if any(pronoun for pronoun in pronouns if pronoun == subj or pronoun == obj): #there's a pronoun subj/obj\n",
    "            ner_tags = row['stanford_ner']\n",
    "            if len([tag for tag in ner_tags if tag==\"PERSON\"]) == length and 'said' not in tokens:\n",
    "                \n",
    "                print('tokens:',tokens)\n",
    "                print('ner_tags:', ner_tags)\n",
    "                print('subj:', tokens[ss:se+1])\n",
    "                print('obj:', tokens[os:oe+1])\n",
    "                \n",
    "                index_person = ner_tags.index('PERSON')\n",
    "                if index_person < len(tokens)-length and ner_tags[index_person:index_person+length] == ['PERSON']*length:\n",
    "                    num_one_person_var += 1\n",
    "                    person = tokens[index_person:index_person+length]\n",
    "                    \n",
    "                    #print_row(row)\n",
    "                if any(pronoun for pronoun in pronouns if pronoun == subj):\n",
    "                    tokens[ss:se+length+1] = person\n",
    "                    ner_tags[ss:se+length+1] = 'PERSON'\n",
    "                    subj_pronoun +=1 \n",
    "                    se = se + length\n",
    "                if any(pronoun for pronoun in pronouns if pronoun == obj):\n",
    "                    tokens[os:oe+length+1] = person\n",
    "                    ner_tags[os:oe+length+1] = 'PERSON'\n",
    "                    obj_pronoun +=1  \n",
    "                    oe = oe + length\n",
    "                    \n",
    "                df.at[index, \"token\"] = tokens\n",
    "                df.at[index, \"stanford_ner\"] = ner_tags\n",
    "                df.at[index, \"subj_end\"] = se\n",
    "                df.at[index, \"obj_end\"] = oe\n",
    "                \n",
    "                print('tokens:',tokens)\n",
    "                print('ner_tags:', ner_tags)\n",
    "                print('subj:', tokens[ss:se+length+1])\n",
    "                print('obj:', tokens[os:oe+length+1])\n",
    "                \n",
    "                break\n",
    "        \n",
    "                \n",
    "                \n",
    "    print(\"Split:\", df_names[i])            \n",
    "    print(\"Of the examples with pronouns, \", num_one_person_var, \" have just {} person ner tag in them.\".format(length))\n",
    "    print(\"Of these examples pronouns, replaced\", subj_pronoun, \" subj as a pronoun\")\n",
    "    print(\"Of these examples pronouns, replaced\", obj_pronoun, \" obj as a pronoun\")\n",
    "    print()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Split: train\n",
    "Of the examples with pronouns,  1783  have just 2 person ner tag in them.\n",
    "Of these examples pronouns, replaced 4190  subj as a pronoun\n",
    "Of these examples pronouns, replaced 2196  obj as a pronoun\n",
    "\n",
    "Split: dev\n",
    "Of the examples with pronouns,  744  have just 2 person ner tag in them.\n",
    "Of these examples pronouns, replaced 1746  subj as a pronoun\n",
    "Of these examples pronouns, replaced 776  obj as a pronoun\n",
    "\n",
    "Split: test\n",
    "Of the examples with pronouns,  651  have just 2 person ner tag in them.\n",
    "Of these examples pronouns, replaced 1698  subj as a pronoun\n",
    "Of these examples pronouns, replaced 752  obj as a pronoun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/dfs/scratch1/simran/tacred/tacred-relation-bootleg/dataset_bootleg_iclr_model/bootleg_model_1002/experiments_noft/everything'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_out = df_train.to_json(r'{}train_coref.json'.format(out_dir),orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_out = df_dev.to_json(r'{}dev_coref.json'.format(out_dir),orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = df_test.to_json(r'{}test_coref.json'.format(out_dir),orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
