{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/dfs/scratch1/simran/tutorial/contextual-embeddings/')\n",
    "import os\n",
    "import random\n",
    "import ujson\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import csv\n",
    "from collections import defaultdict, OrderedDict\n",
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mentions(file): \n",
    "    lines = []\n",
    "    with jsonlines.open(file) as f: \n",
    "        for line in f: \n",
    "            print(line.keys())\n",
    "            new_line = {\n",
    "                'id': line['id'],\n",
    "                'sentence': line['sentence'],\n",
    "                'aliases': line['aliases'], \n",
    "                'spans': line['spans'],\n",
    "                'qids': line['qids'],\n",
    "                #'gold': line['gold'],\n",
    "                'sent_idx_unq': line['sent_idx_unq'],\n",
    "                'gold': line['anchor']\n",
    "            }\n",
    "            lines.append(new_line)\n",
    "    return pd.DataFrame(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/dfs/scratch1/simran/tacred/tacred-relation-bootleg/dataset_bootleg_iclr_model/bootleg_092620/'\n",
    "expt_dir = 'everything/'\n",
    "filename = 'hybrid_with_bootmentions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'sentence', 'aliases', 'spans', 'qids', 'anchor', 'sent_idx_unq', 'aliases_candgen', 'spans_candgen', 'qids_candgen', 'anchors_candgen'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'gold'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-7010decae0c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtacred_data_w_bootleg_mentions_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}{}{}.jsonl'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpt_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#TO FILL IN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbase_mentions_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_mentions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtacred_data_w_bootleg_mentions_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-70-db57f9167f85>\u001b[0m in \u001b[0;36mload_mentions\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;34m'spans'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spans'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;34m'qids'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'qids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0;34m'gold'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gold'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                 \u001b[0;34m'sent_idx_unq'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sent_idx_unq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;34m'gold'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'anchor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gold'"
     ]
    }
   ],
   "source": [
    "tacred_data_w_bootleg_mentions_base = '{}{}{}.jsonl'.format(base_dir, expt_dir, filename) #TO FILL IN \n",
    "base_mentions_df = load_mentions(tacred_data_w_bootleg_mentions_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'sentence', 'aliases', 'spans', 'qids', 'gold', 'sent_idx_unq'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(base_mentions_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              61b3a5c8c9a882dcfcd2                                                                                                                                                                                                                        \n",
      "sentence        Tom Thabane resigned in October last year to form the All Basotho Convention ( ABC ) , crossing the floor with 17 members of parliament , causing constitutional monarch King Letsie III to dissolve parliament and call the snap election .\n",
      "aliases         [tom thabane, all basotho convention, abc, crossing the floor, members of parliament, constitutional monarch, king letsie iii, dissolve parliament, snap election]                                                                          \n",
      "spans           [[0, 2], [10, 13], [14, 15], [17, 20], [22, 25], [27, 29], [29, 32], [33, 35], [38, 40]]                                                                                                                                                    \n",
      "qids            [Q983971, Q1346132, Q169889, Q5188683, Q11010, Q41614, Q57537, Q741182, Q25052149]                                                                                                                                                          \n",
      "gold            [True, True, True, True, True, True, True, True, True]                                                                                                                                                                                      \n",
      "sent_idx_unq    0                                                                                                                                                                                                                                           \n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for ind, row in base_mentions_df.iterrows():\n",
    "    print(row)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add the mentions I want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliases_to_add = {}\n",
    "# based on tacred dev\n",
    "aliases_to_add['millipore'] = {'alias':'merck millipore', 'qid':'Q1669719', 'len':1}\n",
    "aliases_to_add['US'] = {'alias':'united states', 'qid':'Q30', 'len':1}\n",
    "aliases_to_add['U.S.'] = {'alias':'united states', 'qid':'Q30', 'len':1}\n",
    "aliases_to_add['WNO'] = {'alias':\"washington national opera\", 'qid':'Q386613', 'len':1}\n",
    "\n",
    "# based on tacred test\n",
    "# aliases_to_add['UASR'] = {'alias':\"university alliance of the silk road\", 'qid':'Q28187407', 'len':1}\n",
    "# aliases_to_add['NTSO'] = {'alias':\"national taiwan symphony orchestra\", 'qid':'Q6978831', 'len':1}\n",
    "# aliases_to_add['LIHOP'] = {'alias':\"conspiracy theories\", 'qid':'Q22763', 'len':1}\n",
    "# aliases_to_add['ShopperTrak'] = {'alias':\"experian footfall\", 'qid':'Q5421023', 'len':1}\n",
    "# aliases_to_add['TPIPL'] = {'alias':\"tpi polene\", 'qid':'Q7671160', 'len':1}\n",
    "# aliases_to_add['SouthGobi Energy Resources'] = {'alias':\"southgobi resources\", 'qid':'Q65041717', 'len':3}\n",
    "# aliases_to_add['National Energy Administration'] = {'alias':\"national energy commission\", 'qid':'Q6972446', 'len':3}\n",
    "# aliases_to_add['Economic Cooperation Organisation'] = {'alias':\"economic cooperation organization\", 'qid':'Q225950', 'len':3}\n",
    "# aliases_to_add['Election Complaints Commission'] = {'alias': \"election commission\", 'qid':'Q935741', 'len':3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(base_mentions_df['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of times each alias is added is: \n",
      "millipore 0\n",
      "US 529\n",
      "U.S. 1328\n",
      "WNO 0\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "print(\"The number of times each alias is added is: \")\n",
    "for k, v in aliases_to_add.items():\n",
    "    sub_df = base_mentions_df[base_mentions_df['sentence'].str.contains(k)]\n",
    "    count = 0\n",
    "    for ind, row in sub_df.iterrows():\n",
    "        sentence = row['sentence']\n",
    "        alias = row['aliases']\n",
    "        spans = row['spans']\n",
    "        qids = row['qids']\n",
    "        gold = row['gold']\n",
    "        \n",
    "        k_lst = k.split(' ')\n",
    "        if v['qid'] not in qids:\n",
    "            tokens = sentence.split(' ')\n",
    "            if k_lst[0] in tokens:\n",
    "                index = tokens.index(k_lst[0])\n",
    "                if k in ' '.join(tokens[index:index+v['len']]):\n",
    "                    span = [index, index+v['len']]\n",
    "                    #print(row)\n",
    "                    if span not in spans:\n",
    "                        spans.append(span)\n",
    "                        alias.append(v['alias'])\n",
    "                        qids.append(v['qid'])\n",
    "                        gold.append(True)\n",
    "                        base_mentions_df.at[ind, 'aliases'] = alias\n",
    "                        base_mentions_df.at[ind, 'spans'] = spans\n",
    "                        base_mentions_df.at[ind, 'qids'] = qids\n",
    "                        base_mentions_df.at[ind, 'gold'] = gold\n",
    "                        count += 1       \n",
    "                        \n",
    "        assert len(alias) == len(gold), print(row)\n",
    "    print(k, count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# path_json = '{}{}TEMPFILE_{}_w_manual_alias.json'.format(base_dir, expt_dir, filename)\n",
    "# base_mentions_df.to_json(path_json, orient='records')\n",
    "\n",
    "# with open(path_json) as infile:\n",
    "#     data = json.load(infile)\n",
    "#     print(len(data))\n",
    "    \n",
    "all_out = '{}{}{}_w_manual_alias.jsonl'.format(base_dir, expt_dir, filename)\n",
    "with open(all_out, 'w') as outfile:\n",
    "    for d in data:\n",
    "        json.save(d, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dfs/scratch1/simran/tacred/tacred-relation-bootleg/dataset_bootleg_iclr_model/bootleg_092620/manual_alias/all_tacred_w_bootoutput_w_manual_alias.jsonl\n"
     ]
    }
   ],
   "source": [
    "print(all_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
