{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import ujson\n",
    "from tqdm import tqdm\n",
    "from bootleg.symbols.entity_profile import EntityProfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load up the entity profile\n",
    "Inside the cache directory is\n",
    "* entity_mappings: where aliases and entity information is stored\n",
    "* type_mappings: where type information is stored. There will be one subfolder per type system\n",
    "* kg_mappings: where kg information is stored\n",
    "\n",
    "When we load a entity profile, we can put it in `edit_mode` to allow us to make changes. Don't forget to set that flag below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kg_mappings\n",
      "    qid2relations.json\n",
      "    config.json\n",
      "type_mappings\n",
      "    wiki\n",
      "        type_vocab.json\n",
      "        config.json\n",
      "        qid2typeids.json\n",
      "        qid2typenames.json\n",
      "entity_mappings\n",
      "    alias2qids.json\n",
      "    alias2id.json\n",
      "    config.json\n",
      "    filter_stats.json\n",
      "    qid2eid.json\n",
      "    qid2title.json\n"
     ]
    }
   ],
   "source": [
    "entity_profile_cache = Path(\"pretrained_medmentions/pretrained_medmentions_entity_db\")\n",
    "# Print out directory structure\n",
    "for fold in entity_profile_cache.iterdir():\n",
    "    print(fold.name)\n",
    "    for sub_file in fold.iterdir():\n",
    "        print(\"   \", sub_file.name)\n",
    "        if sub_file.is_dir():\n",
    "            for subsub_file in sub_file.iterdir():\n",
    "                print(\"       \", subsub_file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Entity Symbols\n",
      "Loading Type Symbols from /dfs/scratch0/lorr1/projects/bootleg/notebooks/medmentions/pretrained_medmentions/pretrained_medmentions_entity_db/type_mappings/wiki\n",
      "Loading KG Symbols\n",
      "CPU times: user 27.5 s, sys: 2.77 s, total: 30.3 s\n",
      "Wall time: 30.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load up profile data - don't forget to set edit_mode = True\n",
    "ep = EntityProfile.load_from_cache(entity_profile_cache, edit_mode=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see what operations you can call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dir__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_read_profile_file', 'add_entity', 'add_mention', 'add_relation', 'add_type', 'get_all_connections', 'get_all_mentions', 'get_all_qids', 'get_all_types', 'get_all_typesystems', 'get_connections_by_relation', 'get_eid', 'get_entities_of_type', 'get_mentions', 'get_mentions_with_scores', 'get_num_entities_with_pad_and_nocand', 'get_qid_cands', 'get_qid_count_cands', 'get_title', 'get_types', 'is_connected', 'load_from_cache', 'load_from_jsonl', 'mention_exists', 'prune_to_entities', 'qid_exists', 'reidentify_entity', 'remove_mention', 'remove_relation', 'remove_type', 'save', 'update_entity']\n"
     ]
    }
   ],
   "source": [
    "object_methods = [method_name for method_name in dir(ep)\n",
    "                  if callable(getattr(ep, method_name))]\n",
    "\n",
    "print(object_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Cystic fibrosis\n",
      "Mentions: {'cyctic fibrosis', 'cystic fibrose', 'cystic fibrosis allele', 'cystic fibrosis cf', 'mucoviscidose', 'mucoviscidosis', 'cystic fiborsis', 'cistic fibrosis', 'history of cystic fibrosis', 'mucoviscidopsis', 'mucoviscoidosis', 'cystic fibrosis', 'fibrocystic disease of the pancreas', 'treatment of cystic fibrosis', 'mucuviscoidosis', 'gene therapy for cystic fibrosis', 'viscoidosis'}\n",
      "Type Systems: ['wiki']\n",
      "Sample Wikidata Types: ['town in China', 'tehsil of India', 'subdistrict of China', 'faculty', 'pier']\n"
     ]
    }
   ],
   "source": [
    "# Get the title of an entity\n",
    "print(\"Title:\", ep.get_title(\"Q178194\"))\n",
    "\n",
    "# Get mentions for an entity\n",
    "print(\"Mentions:\", ep.get_mentions(\"Q178194\"))\n",
    "\n",
    "# Get type systems\n",
    "print(\"Type Systems:\", ep.get_all_typesystems())\n",
    "\n",
    "# Get some types\n",
    "print(\"Sample Wikidata Types:\", ep.get_all_types(\"wiki\")[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the types\n",
    "\n",
    "Suppose you think the QID Q178194 should really be type `health problem` instead of `disease`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing Types: ['disease', 'designated intractable/rare diseases', 'autosomal recessive disease', 'lung disease']\n",
      "Modified Types: ['designated intractable/rare diseases', 'autosomal recessive disease', 'lung disease', 'health problem']\n"
     ]
    }
   ],
   "source": [
    "# First get existing types\n",
    "qid = \"Q178194\"\n",
    "type_system = \"wiki\"\n",
    "print(\"Existing Types:\", ep.get_types(qid, type_system))\n",
    "\n",
    "# Remove type\n",
    "ep.remove_type(qid, \"disease\", type_system)\n",
    "ep.add_type(qid, \"health problem\", type_system)\n",
    "\n",
    "print(\"Modified Types:\", ep.get_types(qid, type_system))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you think Q178194 should not have the relation P5008 with Q4099686 anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing Connections: {'P910': ['Q8439242'], 'P279': ['Q10267817', 'Q3392853', 'Q55785521', 'Q55785598', 'Q55785522', 'Q55788042', 'Q55788066'], 'P1995': ['Q1071953'], 'P2293': ['Q17816212', 'Q18031550', 'Q18043081', 'Q14864712'], 'P2176': ['Q7553358', 'Q2067922', 'Q419995', 'Q375613', 'Q6095693', 'Q1758380', 'Q418546', 'Q1758380'], 'P31': ['Q12136', 'Q42303753'], 'P463': ['Q1205164'], 'P5008': ['Q4099686']}\n",
      "Modified Connections: {'P910': ['Q8439242'], 'P279': ['Q10267817', 'Q3392853', 'Q55785521', 'Q55785598', 'Q55785522', 'Q55788042', 'Q55788066'], 'P1995': ['Q1071953'], 'P2293': ['Q17816212', 'Q18031550', 'Q18043081', 'Q14864712'], 'P2176': ['Q7553358', 'Q2067922', 'Q419995', 'Q375613', 'Q6095693', 'Q1758380', 'Q418546', 'Q1758380'], 'P31': ['Q12136', 'Q42303753'], 'P463': ['Q1205164']}\n"
     ]
    }
   ],
   "source": [
    "qid = \"Q178194\"\n",
    "print(\"Existing Connections:\", ep.get_all_connections(qid))\n",
    "\n",
    "# Remove relation\n",
    "ep.remove_relation(qid, \"P5008\", \"Q4099686\")\n",
    "\n",
    "print(\"Modified Connections:\", ep.get_all_connections(qid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add missing entities\n",
    "\n",
    "Our goal in this exercise is to modify the entity profile to work with a finetuning dataset.\n",
    "\n",
    "As a little primer, this entity profile was constructed over a Wikipedia subset of relevant medical QIDs for this MedMentions benchmark. However, we have two problems\n",
    "* some QIDs need to be mapped to the MedMentions ID set (CUIs)\n",
    "* some CUIs are not in the list and need to be added\n",
    "\n",
    "Let's first map the QIDs we have to the CUIs given a preexisting mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1849087']\n"
     ]
    }
   ],
   "source": [
    "qid2cui = ujson.load(open(entity_profile_cache.parent / \"qid2cui.json\"))\n",
    "cui2qid = ujson.load(open(entity_profile_cache.parent / \"cui2qid.json\"))\n",
    "print(qid2cui[\"Q24977255\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21926/21926 [00:00<00:00, 25295.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Total Wikidata UMLS QIDS 21926, Total QIDs in Wikipedia 9090\n"
     ]
    }
   ],
   "source": [
    "# Remap QID -> CUI\n",
    "total_qids = len(qid2cui)\n",
    "found_qids = 0\n",
    "dropped_qids = set()\n",
    "final_remap = {}\n",
    "for qid in tqdm(qid2cui, total=len(qid2cui)):\n",
    "    if ep.qid_exists(qid):\n",
    "        found_qids += 1\n",
    "        new_cui = list(qid2cui[qid])[0]\n",
    "        final_remap[qid] = new_cui\n",
    "        ep.reidentify_entity(qid, new_cui)\n",
    "    else:\n",
    "        dropped_qids.add(qid)\n",
    "        \n",
    "        \n",
    "ujson.dump(final_remap, open(entity_profile_cache.parent / \"oldqid2cui_finalmap.json\", \"w\"))\n",
    "print(ep.qid_exists(\"Q24977255\"))\n",
    "print(f\"Total Wikidata UMLS QIDS {total_qids}, Total QIDs in Wikipedia {found_qids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q21097760', 'Q18554206', 'Q18557056', 'Q18554405', 'Q1440338', 'Q55782026', 'Q18556829', 'Q18553987', 'Q18558049', 'Q18556822']\n"
     ]
    }
   ],
   "source": [
    "print(list(dropped_qids)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add the new CUIs. The tricky think is going to be adding the types of the CUIs. Below we have provided a heurisitc mapping for UMLS types to the types in our type system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_type2wikitype = {\n",
    "     \"Chemical\":[\"chemical compound\", \"chemical substance\"],\n",
    "     \"Anatomical Structure\": ['anatomical structure'],\n",
    "     \"Intellectual Product\": ['intellectual property'],\n",
    "     \"Spatial Concept\": ['concept'],\n",
    "     \"Finding\": ['medical finding'],\n",
    "     \"Biologic Function\": ['biological process', 'biological system'],\n",
    "     \"Organization\": ['organization'],\n",
    "     \"Health Care Activity\": ['health care'],\n",
    "     \"Research Activity\": ['research project'],\n",
    "     \"Eukaryote\": ['eukaryote'],\n",
    "     \"Medical Device\": ['medical device'],\n",
    "     \"Injury or Poisoning\": ['injury', 'poisoning'],\n",
    "     \"Clinical Attribute\": ['clinical sign', 'clinical finding'],\n",
    "     \"Professional or Occupational Group\": ['group'],\n",
    "     \"Bacterium\": ['bacteria'],\n",
    "     \"Biomedical Occupation or Discipline\": ['paramedical speciality'],\n",
    "     \"Virus\": ['virus'],\n",
    "     \"Population Group\": ['population group'],\n",
    "     \"Food\": ['food'],\n",
    "     \"Body Substance\": ['body fluids'],\n",
    "     \"Body System\": ['biological system']\n",
    "}\n",
    "# We'll need the titles\n",
    "medmentions_cui2title = ujson.load(open(entity_profile_cache.parent / \"mm_cui2title.json\"))\n",
    "medmentions_cui2typename = ujson.load(open(entity_profile_cache.parent / \"mm_types2typename.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add a new entity, we need to provide the following json object to our entity profile\n",
    "```\n",
    "{\n",
    "    \"entity_id\": \"C000\",\n",
    "    \"mentions\": [[\"dog\", 10.0], [\"dogg\", 7.0], [\"animal\", 4.0]],\n",
    "    \"title\": \"Dog\",\n",
    "    \"types\": {\"hyena\": [\"animal\"], \"wiki\": [\"dog\"]},\n",
    "    \"relations\": [\n",
    "        {\"relation\": \"sibling\", \"object\": \"Q345\"},\n",
    "        {\"relation\": \"sibling\", \"object\": \"Q567\"},\n",
    "    ],\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 397524/397524 [00:22<00:00, 17297.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13835 6442 397524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total = len(medmentions_cui2title)\n",
    "cnt = 0\n",
    "dnt = 0\n",
    "for i, cui in tqdm(enumerate(medmentions_cui2title), total=len(medmentions_cui2title)):\n",
    "    title = medmentions_cui2title[cui]\n",
    "    cui_types = []\n",
    "    for j in medmentions_cui2typename.get(cui, []):\n",
    "        cui_types.extend(mm_type2wikitype[j])\n",
    "    d = {\n",
    "        \"entity_id\": cui,\n",
    "        \"mentions\": [[title.lower(), 10.0]],\n",
    "        \"title\": title,\n",
    "        \"types\": {\"wiki\": cui_types},\n",
    "    }\n",
    "    if cui in cui2qid:\n",
    "        cnt += 1\n",
    "    if ep.qid_exists(cui):\n",
    "        dnt += 1\n",
    "    else:\n",
    "        ep.add_entity(d)\n",
    "print(cnt, dnt, total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unused entities\n",
    "\n",
    "Lastly, for space reasons, it'd be nice to remove the QIDs that are no longer needed in this dump. For that, we can call `prune_to_entities`. This operation will remove all entities not in the set of entities given. In will throw an error, however, if you ask it to remove an entity that doesn't exist.\n",
    "\n",
    "**Important** we with *reindex* the entities after this call. You *must* call the `fit_to_profile` method described below for these changes to take affect with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 397524/397524 [00:00<00:00, 811213.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get entities to keep\n",
    "entities_to_keep = set(medmentions_cui2title.keys())\n",
    "# Make sure they are all in the dump\n",
    "for qid in tqdm(entities_to_keep):\n",
    "    if not ep.qid_exists(qid):\n",
    "        print(f\"{qid} does not exists\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting number of entities: {len(ep.get_all_qids())}\")\n",
    "ep.prune_to_entities(entities_to_keep)\n",
    "print(f\"Ending number of entities: {len(ep.get_all_qids())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model\n",
    "\n",
    "We'll skip this part as bulk upload isn't ready yet. But, once you have the final profile, if your model has entity embeddings, you'd run the following to \"refit\" your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep.save(entity_profile_cache.parent / \"new_profile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(medmentions_cui2title)\n",
    "cnt = 0\n",
    "for cui in cui2qid:\n",
    "    if cui in medmentions_cui2title:\n",
    "        cnt += 1\n",
    "        \n",
    "print(cnt, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 -m bootleg.utils.entity_profile.fit_to_profile \\\n",
    "--new_entity_profile new_profile\\\n",
    "--train_entity_profile pretrained_medmentions_entity_db \\\n",
    "--model_path model/last_model.pth \\\n",
    "--save_model_path model/altered_model.pth \\\n",
    "--oldqid2newqid oldqid2cui_finalmap.json \\\n",
    "--init_vec model/init_vec_from_model.npy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
