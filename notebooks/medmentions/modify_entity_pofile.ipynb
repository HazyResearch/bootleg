{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import ujson\n",
    "from tqdm import tqdm\n",
    "from bootleg.symbols.entity_profile import EntityProfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load up the entity profile\n",
    "Inside the cache directory is\n",
    "* entity_mappings: where aliases and entity information is stored\n",
    "* type_mappings: where type information is stored. There will be one subfolder per type system\n",
    "* kg_mappings: where kg information is stored\n",
    "\n",
    "When we load a entity profile, we can put it in `edit_mode` to allow us to make changes. Don't forget to set that flag below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kg_mappings\n",
      "    qid2relations.json\n",
      "    config.json\n",
      "type_mappings\n",
      "    wiki\n",
      "        type_vocab.json\n",
      "        config.json\n",
      "        qid2typeids.json\n",
      "        qid2typenames.json\n",
      "entity_mappings\n",
      "    alias2qids.json\n",
      "    alias2id.json\n",
      "    config.json\n",
      "    filter_stats.json\n",
      "    qid2eid.json\n",
      "    qid2title.json\n"
     ]
    }
   ],
   "source": [
    "entity_profile_cache = Path(\"/dfs/scratch0/lorr1/projects/bootleg/notebooks/medmentions/pretrained_medmentions/pretrained_medmentions_entity_db\")\n",
    "# Print out directory structure\n",
    "for fold in entity_profile_cache.iterdir():\n",
    "    print(fold.name)\n",
    "    for sub_file in fold.iterdir():\n",
    "        print(\"   \", sub_file.name)\n",
    "        if sub_file.is_dir():\n",
    "            for subsub_file in sub_file.iterdir():\n",
    "                print(\"       \", subsub_file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Entity Symbols\n",
      "Loading Type Symbols from /dfs/scratch0/lorr1/projects/bootleg/notebooks/medmentions/pretrained_medmentions/pretrained_medmentions_entity_db/type_mappings/wiki\n",
      "Loading KG Symbols\n",
      "CPU times: user 27.5 s, sys: 2.77 s, total: 30.3 s\n",
      "Wall time: 30.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load up profile data - don't forget to set edit_mode = True\n",
    "ep = EntityProfile.load_from_cache(entity_profile_cache, edit_mode=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see what operations you can call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dir__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_read_profile_file', 'add_entity', 'add_mention', 'add_relation', 'add_type', 'get_all_connections', 'get_all_mentions', 'get_all_qids', 'get_all_types', 'get_all_typesystems', 'get_connections_by_relation', 'get_eid', 'get_entities_of_type', 'get_mentions', 'get_mentions_with_scores', 'get_num_entities_with_pad_and_nocand', 'get_qid_cands', 'get_qid_count_cands', 'get_title', 'get_types', 'is_connected', 'load_from_cache', 'load_from_jsonl', 'mention_exists', 'prune_to_entities', 'qid_exists', 'reidentify_entity', 'remove_mention', 'remove_relation', 'remove_type', 'save', 'update_entity']\n"
     ]
    }
   ],
   "source": [
    "object_methods = [method_name for method_name in dir(ep)\n",
    "                  if callable(getattr(ep, method_name))]\n",
    "\n",
    "print(object_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Cystic fibrosis\n",
      "Mentions: {'cyctic fibrosis', 'cystic fibrose', 'cystic fibrosis allele', 'cystic fibrosis cf', 'mucoviscidose', 'mucoviscidosis', 'cystic fiborsis', 'cistic fibrosis', 'history of cystic fibrosis', 'mucoviscidopsis', 'mucoviscoidosis', 'cystic fibrosis', 'fibrocystic disease of the pancreas', 'treatment of cystic fibrosis', 'mucuviscoidosis', 'gene therapy for cystic fibrosis', 'viscoidosis'}\n",
      "Type Systems: ['wiki']\n",
      "Sample Wikidata Types: ['town in China', 'tehsil of India', 'subdistrict of China', 'faculty', 'pier']\n"
     ]
    }
   ],
   "source": [
    "# Get the title of an entity\n",
    "print(\"Title:\", ep.get_title(\"Q178194\"))\n",
    "\n",
    "# Get mentions for an entity\n",
    "print(\"Mentions:\", ep.get_mentions(\"Q178194\"))\n",
    "\n",
    "# Get type systems\n",
    "print(\"Type Systems:\", ep.get_all_typesystems())\n",
    "\n",
    "# Get some types\n",
    "print(\"Sample Wikidata Types:\", ep.get_all_types(\"wiki\")[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the types\n",
    "\n",
    "Suppose you think the QID Q178194 should really be type `health problem` instead of `disease`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing Types: ['disease', 'designated intractable/rare diseases', 'autosomal recessive disease', 'lung disease']\n",
      "Modified Types: ['designated intractable/rare diseases', 'autosomal recessive disease', 'lung disease', 'health problem']\n"
     ]
    }
   ],
   "source": [
    "# First get existing types\n",
    "qid = \"Q178194\"\n",
    "type_system = \"wiki\"\n",
    "print(\"Existing Types:\", ep.get_types(qid, type_system))\n",
    "\n",
    "# Remove type\n",
    "ep.remove_type(qid, \"disease\", type_system)\n",
    "ep.add_type(qid, \"health problem\", type_system)\n",
    "\n",
    "print(\"Modified Types:\", ep.get_types(qid, type_system))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you think Q178194 should not have the relation P5008 with Q4099686 anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing Connections: {'P910': ['Q8439242'], 'P279': ['Q10267817', 'Q3392853', 'Q55785521', 'Q55785598', 'Q55785522', 'Q55788042', 'Q55788066'], 'P1995': ['Q1071953'], 'P2293': ['Q17816212', 'Q18031550', 'Q18043081', 'Q14864712'], 'P2176': ['Q7553358', 'Q2067922', 'Q419995', 'Q375613', 'Q6095693', 'Q1758380', 'Q418546', 'Q1758380'], 'P31': ['Q12136', 'Q42303753'], 'P463': ['Q1205164'], 'P5008': ['Q4099686']}\n",
      "Modified Connections: {'P910': ['Q8439242'], 'P279': ['Q10267817', 'Q3392853', 'Q55785521', 'Q55785598', 'Q55785522', 'Q55788042', 'Q55788066'], 'P1995': ['Q1071953'], 'P2293': ['Q17816212', 'Q18031550', 'Q18043081', 'Q14864712'], 'P2176': ['Q7553358', 'Q2067922', 'Q419995', 'Q375613', 'Q6095693', 'Q1758380', 'Q418546', 'Q1758380'], 'P31': ['Q12136', 'Q42303753'], 'P463': ['Q1205164']}\n"
     ]
    }
   ],
   "source": [
    "qid = \"Q178194\"\n",
    "print(\"Existing Connections:\", ep.get_all_connections(qid))\n",
    "\n",
    "# Remove relation\n",
    "ep.remove_relation(qid, \"P5008\", \"Q4099686\")\n",
    "\n",
    "print(\"Modified Connections:\", ep.get_all_connections(qid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add missing entities\n",
    "\n",
    "Our goal in this exercise is to modify the entity profile to work with a finetuning dataset.\n",
    "\n",
    "As a little primer, this entity profile was constructed over a Wikipedia subset of relevant medical QIDs for this MedMentions benchmark. However, we have two problems\n",
    "* some QIDs need to be mapped to the MedMentions ID set (CUIs)\n",
    "* some CUIs are not in the list and need to be added\n",
    "\n",
    "Let's first map the QIDs we have to the CUIs given a preexisting mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1849087']\n"
     ]
    }
   ],
   "source": [
    "qid2cui = ujson.load(open(entity_profile_cache.parent / \"qid2cui.json\"))\n",
    "cui2qid = ujson.load(open(entity_profile_cache.parent / \"cui2qid.json\"))\n",
    "print(qid2cui[\"Q24977255\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21926/21926 [00:00<00:00, 25295.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Total Wikidata UMLS QIDS 21926, Total QIDs in Wikipedia 9090\n"
     ]
    }
   ],
   "source": [
    "# Remap QID -> CUI\n",
    "total_qids = len(qid2cui)\n",
    "found_qids = 0\n",
    "dropped_qids = set()\n",
    "final_remap = {}\n",
    "for qid in tqdm(qid2cui, total=len(qid2cui)):\n",
    "    if ep.qid_exists(qid):\n",
    "        found_qids += 1\n",
    "        new_cui = list(qid2cui[qid])[0]\n",
    "        final_remap[qid] = new_cui\n",
    "        ep.reidentify_entity(qid, new_cui)\n",
    "    else:\n",
    "        dropped_qids.add(qid)\n",
    "        \n",
    "        \n",
    "ujson.dump(final_remap, open(entity_profile_cache.parent / \"oldqid2cui_finalmap.json\", \"w\"))\n",
    "print(ep.qid_exists(\"Q24977255\"))\n",
    "print(f\"Total Wikidata UMLS QIDS {total_qids}, Total QIDs in Wikipedia {found_qids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q21097760', 'Q18554206', 'Q18557056', 'Q18554405', 'Q1440338', 'Q55782026', 'Q18556829', 'Q18553987', 'Q18558049', 'Q18556822']\n"
     ]
    }
   ],
   "source": [
    "print(list(dropped_qids)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add the new CUIs. The tricky think is going to be adding the types of the CUIs. Below we have provided a heurisitc mapping for UMLS types to the types in our type system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_type2wikitype = {\n",
    "     \"Chemical\":[\"chemical compound\", \"chemical substance\"],\n",
    "     \"Anatomical Structure\": ['anatomical structure'],\n",
    "     \"Intellectual Product\": ['intellectual property'],\n",
    "     \"Spatial Concept\": ['concept'],\n",
    "     \"Finding\": ['medical finding'],\n",
    "     \"Biologic Function\": ['biological process', 'biological system'],\n",
    "     \"Organization\": ['organization'],\n",
    "     \"Health Care Activity\": ['health care'],\n",
    "     \"Research Activity\": ['research project'],\n",
    "     \"Eukaryote\": ['eukaryote'],\n",
    "     \"Medical Device\": ['medical device'],\n",
    "     \"Injury or Poisoning\": ['injury', 'poisoning'],\n",
    "     \"Clinical Attribute\": ['clinical sign', 'clinical finding'],\n",
    "     \"Professional or Occupational Group\": ['group'],\n",
    "     \"Bacterium\": ['bacteria'],\n",
    "     \"Biomedical Occupation or Discipline\": ['paramedical speciality'],\n",
    "     \"Virus\": ['virus'],\n",
    "     \"Population Group\": ['population group'],\n",
    "     \"Food\": ['food'],\n",
    "     \"Body Substance\": ['body fluids'],\n",
    "     \"Body System\": ['biological system']\n",
    "}\n",
    "# We'll need the titles\n",
    "medmentions_cui2title = ujson.load(open(entity_profile_cache.parent / \"mm_cui2title.json\"))\n",
    "medmentions_cui2typename = ujson.load(open(entity_profile_cache.parent / \"mm_types2typename.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add a new entity, we need to provide the following json object to our entity profile\n",
    "```\n",
    "{\n",
    "    \"entity_id\": \"C000\",\n",
    "    \"mentions\": [[\"dog\", 10.0], [\"dogg\", 7.0], [\"animal\", 4.0]],\n",
    "    \"title\": \"Dog\",\n",
    "    \"types\": {\"hyena\": [\"animal\"], \"wiki\": [\"dog\"]},\n",
    "    \"relations\": [\n",
    "        {\"relation\": \"sibling\", \"object\": \"Q345\"},\n",
    "        {\"relation\": \"sibling\", \"object\": \"Q567\"},\n",
    "    ],\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 397524/397524 [00:22<00:00, 17297.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13835 6442 397524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total = len(medmentions_cui2title)\n",
    "cnt = 0\n",
    "dnt = 0\n",
    "for i, cui in tqdm(enumerate(medmentions_cui2title), total=len(medmentions_cui2title)):\n",
    "    title = medmentions_cui2title[cui]\n",
    "    cui_types = []\n",
    "    for j in medmentions_cui2typename.get(cui, []):\n",
    "        cui_types.extend(mm_type2wikitype[j])\n",
    "    d = {\n",
    "        \"entity_id\": cui,\n",
    "        \"mentions\": [[title.lower(), 10.0]],\n",
    "        \"title\": title,\n",
    "        \"types\": {\"wiki\": cui_types},\n",
    "    }\n",
    "    if cui in cui2qid:\n",
    "        cnt += 1\n",
    "    if ep.qid_exists(cui):\n",
    "        dnt += 1\n",
    "    else:\n",
    "        ep.add_entity(d)\n",
    "print(cnt, dnt, total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unused entities\n",
    "\n",
    "Lastly, for space reasons, it'd be nice to remove the QIDs that are no longer needed in this dump. For that, we can call `prune_to_entities`. This operation will remove all entities not in the set of entities given. In will throw an error, however, if you ask it to remove an entity that doesn't exist.\n",
    "\n",
    "**Important** we with *reindex* the entities after this call. You *must* call the `fit_to_profile` method described below for these changes to take affect with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 397524/397524 [00:00<00:00, 811213.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get entities to keep\n",
    "entities_to_keep = set(medmentions_cui2title.keys())\n",
    "# Make sure they are all in the dump\n",
    "for qid in tqdm(entities_to_keep):\n",
    "    if not ep.qid_exists(qid):\n",
    "        print(f\"{qid} does not exists\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting number of entities: {len(ep.get_all_qids())}\")\n",
    "ep.prune_to_entities(entities_to_keep)\n",
    "print(f\"Ending number of entities: {len(ep.get_all_qids())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model\n",
    "\n",
    "We'll skip this part as bulk upload isn't ready yet. But, once you have the final profile, if your model has entity embeddings, you'd run the following to \"refit\" your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep.save(entity_profile_cache.parent / \"new_profile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(medmentions_cui2title)\n",
    "cnt = 0\n",
    "for cui in cui2qid:\n",
    "    if cui in medmentions_cui2title:\n",
    "        cnt += 1\n",
    "        \n",
    "print(cnt, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 -m bootleg.utils.entity_profile.fit_to_profile \\\n",
    "--new_entity_profile new_profile\\\n",
    "--train_entity_profile pretrained_medmentions_entity_db \\\n",
    "--model_path model/last_model.pth \\\n",
    "--save_model_path model/altered_model.pth \\\n",
    "--oldqid2newqid oldqid2cui_finalmap.json \\\n",
    "--init_vec model/init_vec_from_model.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract MedMentions Wikidata Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dir = Path(\"/dfs/scratch0/lorr1/projects/bootleg-data/embs\")\n",
    "title2typeqid = ujson.load(open(emb_dir / \"wikidatatitle_to_typeqid_1229.json\"))\n",
    "title2typeid = ujson.load(open(emb_dir / \"wikidatatitle_to_typeid_1229.json\"))\n",
    "typeid2title = {v:k for k,v in title2typeid.items()}\n",
    "qid2typeid = ujson.load(open(emb_dir / \"wikidata_types_1229.json\"))\n",
    "qid2cnt = ujson.load(open(emb_dir.parent / \"data\" / \"wiki_title_0122\" / \"qid_cnts_train.json\"))\n",
    "qid2title = ujson.load(open(emb_dir.parent / \"data\" / \"wiki_title_0122\" / \"entity_db\" / \"entity_mappings\" / \"qid2title.json\"))\n",
    "type_names = ujson.load(open(\"/dfs/scratch0/lorr1/projects/bootleg-data/data/medmentions_0203/spacy_10_exp_noNC/embs/type_vocab.json\"))\n",
    "entity_profile_cache = Path(\"/dfs/scratch0/lorr1/projects/bootleg/notebooks/medmentions/pretrained_medmentions/pretrained_medmentions_entity_db\")\n",
    "qid2cui = ujson.load(open(entity_profile_cache.parent / \"qid2cui.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chemical', 'Anatomical Structure', 'Intellectual Product', 'Spatial Concept', 'Finding', 'Biologic Function', 'Organization', 'Health Care Activity', 'Research Activity', 'Eukaryote', 'Medical Device', 'Injury or Poisoning', 'Clinical Attribute', 'Professional or Occupational Group', 'Bacterium', 'Biomedical Occupation or Discipline', 'Virus', 'Population Group', 'Food', 'Body Substance', 'Body System']\n"
     ]
    }
   ],
   "source": [
    "all_umls_names = list(type_names.keys())\n",
    "print(all_umls_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "research institute\n",
      "researcher\n",
      "Cooperative Science and Research Body\n",
      "research group\n",
      "medical researcher\n",
      "Antarctic research station\n",
      "research fellow\n",
      "artificial intelligence researcher\n",
      "public research university\n",
      "research vessel\n",
      "research project\n",
      "research station\n",
      "research expedition\n",
      "research program\n",
      "research center\n",
      "university research group\n",
      "human subject research\n",
      "research method\n",
      "research reactor\n",
      "research object\n",
      "Higher education and research cluster\n",
      "research university\n",
      "mixed research unit\n",
      "research\n",
      "research library\n",
      "research council\n",
      "research assistant\n",
      "research consortium\n",
      "economic research institute\n",
      "medical research center\n",
      "Crown Research Institute\n",
      "medical research institute\n",
      "peace researcher\n",
      "public research institution\n",
      "research network\n",
      "Royal Research Ship\n",
      "medical research\n",
      "market research\n",
      "Public Scientific and Technical Research Establishment\n",
      "contract research organization\n",
      "research funding\n",
      "federally funded research and development center\n",
      "Banner class enviromental research ship\n",
      "National Research University\n"
     ]
    }
   ],
   "source": [
    "s = \"research\"\n",
    "for tyn in title2typeqid:\n",
    "    if s in tyn.lower():\n",
    "        print(tyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23413/23413 [00:00<00:00, 75571.50it/s]\n",
      "100%|██████████| 21926/21926 [00:00<00:00, 751428.35it/s]\n",
      "100%|██████████| 1243/1243 [00:00<00:00, 1150887.39it/s]\n",
      "  2%|▏         | 116334/5832699 [00:00<00:04, 1163338.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242\n",
      "1243\n",
      "1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5832699/5832699 [00:03<00:00, 1516760.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468274\n"
     ]
    }
   ],
   "source": [
    "# Took the ones I wanted from type_names\n",
    "t = [\"chemical\", \"anatomical structure\", \"anatomy\", \"anatomical\", \"intellectual property\", \"medical organization\", \"concept\", \"biological\", \"health care\", \"medical researcher\", \n",
    "     \"eukaryote\", \"medical\", \"injury\", \"poisoning\", \"clinical\", \"bacterium\", \"bacteria\", \"paramedical speciality\", \"paramedical\" \"biomedical\", \"virus\", \"body substance\", \n",
    "     \"population group\", \"food\", \"body fluids\"]\n",
    "t_exact = [\"research\"]\n",
    "t_remove = []\n",
    "qids_remove = set()\n",
    "\n",
    "types_to_keep = set()\n",
    "# Add it types related to the umls type words\n",
    "for ty in tqdm(title2typeqid, total=len(title2typeqid)):\n",
    "    if any(ts.lower() in ty.lower() for ts in t) or any(ts.lower in t_exact for ts in t):\n",
    "        types_to_keep.add(ty)\n",
    "print(len(types_to_keep))\n",
    "\n",
    "# Add all types of the QIDs that are known to be CUIs\n",
    "j = 0\n",
    "for qid in tqdm(qid2cui, total=len(qid2cui)):\n",
    "    for tid in qid2typeid.get(qid, []):\n",
    "        types_to_keep.add(typeid2title[tid])\n",
    "        if j < 20:\n",
    "            j += 1\n",
    "print(len(types_to_keep))\n",
    "\n",
    "# Remove types that are super popular and we don't want\n",
    "for t in t_remove:\n",
    "    if t in types_to_keep:\n",
    "        types_to_keep.remove(t)\n",
    "print(len(types_to_keep))\n",
    "        \n",
    "ids_to_keep = set()\n",
    "for ty in tqdm(types_to_keep):\n",
    "    ids_to_keep.add(title2typeid[ty])\n",
    "\n",
    "\n",
    "qids_to_keep = []\n",
    "for qid in tqdm(qid2typeid, total=len(qid2typeid)):\n",
    "    if qid in qids_remove:\n",
    "        continue\n",
    "    for tid in qid2typeid[qid]:\n",
    "        if tid in ids_to_keep:\n",
    "            qids_to_keep.append(qid)\n",
    "            break\n",
    "\n",
    "print(len(qids_to_keep))\n",
    "# len(qids_to_keep) 22467\n",
    "ujson.dump(qids_to_keep, open(\"medmentions_qids_0306.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q11059 Sanskrit ['language', 'academic discipline', 'ancient language', 'Prakrit']\n",
      "Q388 Linux ['group', 'free software', 'Unix-like']\n",
      "Q48268 International Union for Conservation of Nature ['online database', 'non-governmental organization', 'biological database']\n",
      "Q204711 Food and Drug Administration ['United States federal agency', 'food safety organisation']\n",
      "Q132980 Crambidae ['taxon']\n",
      "Q205295 Longhorn beetle ['taxon']\n",
      "Q12199 HIV/AIDS ['disease', 'syndrome', 'acquired immunodeficiency', 'endemic disease', 'human immunodeficiency virus infectious disease']\n",
      "Q28953 Tortricidae ['taxon']\n",
      "Q169930 Extended play ['musical term', 'type of manufactured good', 'release']\n",
      "Q25341 Passerine ['taxon']\n",
      "Q84263196 Coronavirus disease 2019 ['zoonosis', 'pneumonia', 'atypical pneumonia', 'viral pneumonia', 'coronavirus disease', 'emerging communicable disease']\n",
      "Q459180 Noctuidae ['taxon']\n",
      "Q484876 Chief executive officer ['profession', 'corporate title', 'legal concept', 'leader of organisation', 'chief officer']\n",
      "Q2068481 Erebidae ['taxon']\n",
      "Q136208 ZIP Code ['unique identifier', 'postal code']\n",
      "Q134556 Single (music) ['musical term', 'release']\n",
      "Q7430 DNA ['structural class of chemical compounds', 'biomolecule', 'nucleic acid']\n",
      "Q81068910 COVID-19 pandemic ['disease outbreak', 'public health emergency of international concern', 'pandemic']\n",
      "Q45559 Geometer moth ['taxon']\n"
     ]
    }
   ],
   "source": [
    "for q in qids_to_keep:\n",
    "    if qid2cnt.get(q, 0) > 5000:\n",
    "        print(q, qid2title[q], [typeid2title[qt] for qt in qid2typeid.get(q, [])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
