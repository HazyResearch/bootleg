{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, sys\n",
    "from tutorials.utils import load_train_data, score_predictions\n",
    "import ujson as json\n",
    "import jsonlines\n",
    "from tqdm import tqdm\n",
    "from itertools import chain, islice\n",
    "import random\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from bootleg.symbols.entity_symbols import EntitySymbols\n",
    "from bootleg.symbols.type_symbols import TypeSymbols\n",
    "import shutil\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading entity symbols\n",
      "Loading types from /dfs/scratch0/lorr1/projects/bootleg-data/data/medmentions_0203/spacy_10_doc_exp_noNC/embs/qid2types.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading /dfs/scratch0/lorr1/projects/bootleg-data/data/medmentions_0203/spacy_10_doc_exp_noNC/embs/qid2types.json: 100%|██████████| 202292/202292 [00:00<00:00, 331406.86it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"/dfs/scratch0/lorr1/projects/bootleg-data/data/medmentions_0203\")\n",
    "data_subfolder = \"spacy_10_doc_exp_noNC\"\n",
    "emb_dir = data_dir / data_subfolder / \"embs\"\n",
    "train_file = data_dir / data_subfolder / \"train.jsonl\"\n",
    "test_file = data_dir / data_subfolder / \"test.jsonl\"\n",
    "dev_file = data_dir / data_subfolder / \"dev.jsonl\"\n",
    "print(f\"Loading entity symbols\")\n",
    "es = EntitySymbols(load_dir = data_dir / data_subfolder / \"entity_db/entity_mappings\")\n",
    "a2q = es.get_alias2qids()\n",
    "q2title = es.get_qid2title()\n",
    "types_sym = TypeSymbols(es, emb_dir, max_types=3, type_vocab_file=\"type_vocab.json\", type_file=\"qid2types.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_columns(df, qid2cnt):\n",
    "    if \"cands\" in df:\n",
    "        df[\"num_cands\"] = df[\"cands\"].apply(lambda x: len(x))\n",
    "        df[\"cand_names\"] = df[\"cands\"].apply(lambda x: [y[0] for y in x])\n",
    "        df[\"cand_probs\"] = df[\"cands\"].apply(lambda x: [y[1] for y in x])\n",
    "        del df[\"cands\"]\n",
    "    df[\"span\"] = df[\"span\"].apply(lambda x: tuple(x))\n",
    "    df[\"in_cand\"] = df.apply(lambda x: x[\"gold_title\"] in x[\"cand_names\"], axis=1)\n",
    "    df[\"qid_cnt\"] = df[\"gold_qid\"].apply(lambda x: qid2cnt.get(x, 0))\n",
    "    df[\"pred_qid_cnt\"] = df[\"pred_qid\"].apply(lambda x: qid2cnt.get(x, 0))\n",
    "    df = df[df[\"pred_qid\"] != -1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid2cnt = defaultdict(int)\n",
    "with jsonlines.open(train_file) as in_f:\n",
    "    for line in in_f:\n",
    "        for qid in line[\"qids\"]:\n",
    "            qid2cnt[qid] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2635/2635 [00:02<00:00, 934.69it/s] \n",
      "100%|██████████| 878/878 [00:01<00:00, 578.53it/s] \n"
     ]
    }
   ],
   "source": [
    "train_df = load_train_data(\n",
    "    train_file, q2title, cands_map=a2q, type_symbols=[types_sym], kg_symbols=None\n",
    ")\n",
    "dev_df = load_train_data(\n",
    "    dev_file, q2title, cands_map=a2q, type_symbols=[types_sym], kg_symbols=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_fuzz_score(df):\n",
    "    crc = 0\n",
    "    no_cands = 0\n",
    "    for i, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        cand_names = row[\"cand_names\"]\n",
    "        if len(cand_names) == 0:\n",
    "            no_cands += 1\n",
    "            continue\n",
    "        sp_l, sp_r = row[\"span\"]\n",
    "        al = \" \".join(row[\"sentence\"].split()[sp_l:sp_r])\n",
    "        r = process.extractOne(al, cand_names)\n",
    "    #     print(row[\"cands\"], r)\n",
    "        gld = row[\"gold_title\"]\n",
    "        if r[0] == gld:\n",
    "            crc += 1\n",
    "\n",
    "\n",
    "    print(crc, no_cands, df.shape[0], crc/(df.shape[0]-no_cands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TRAIN\")\n",
    "compute_fuzz_score(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_data(orig, new):\n",
    "    org = 0\n",
    "    kp = 0\n",
    "    with open(orig) as in_f, open(new, \"w\") as out_f:\n",
    "        for line in tqdm(in_f, total=sum(1 for _ in open(orig))):\n",
    "            line = json.loads(line)\n",
    "            new_line = {\n",
    "                \"aliases\": [],\n",
    "                \"qids\": [],\n",
    "                \"spans\": [],\n",
    "                \"gold\": [],\n",
    "                \"sentence\": \"\",\n",
    "                \"sent_idx_unq\": -1,\n",
    "                \"doc_id\": -1\n",
    "            }\n",
    "            for al, sp, gld in zip(line[\"aliases\"], line[\"spans\"], line[\"qids\"]):\n",
    "                org += 1\n",
    "                cand_names = [q2title[p[0]] for p in a2q[al]]\n",
    "                if len(cand_names) == 0:\n",
    "                    continue\n",
    "                sp_l, sp_r = sp\n",
    "                al2 = \" \".join(line[\"sentence\"].split()[sp_l:sp_r])\n",
    "                r = process.extractOne(al2, cand_names)\n",
    "                if r[0] == q2title[gld]:\n",
    "                    kp += 1\n",
    "                    new_line[\"aliases\"].append(al)\n",
    "                    new_line[\"spans\"].append(sp)\n",
    "                    new_line[\"qids\"].append(gld)\n",
    "                    new_line[\"gold\"].append(True)\n",
    "                    new_line[\"doc_id\"] = line[\"doc_id\"]\n",
    "                    new_line[\"sentence\"] = line[\"sentence\"]\n",
    "                    new_line[\"sent_idx_unq\"] = line[\"sent_idx_unq\"]\n",
    "            if new_line[\"doc_id\"] != -1:\n",
    "                out_f.write(json.dumps(new_line) + \"\\n\")\n",
    "\n",
    "    print(f\"Kept: {kp} Our of: {org}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2487/26993 [00:05<00:55, 439.14it/s]WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '( - )']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '( - )']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '( - )']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '( - )']\n",
      " 33%|███▎      | 8949/26993 [00:21<00:42, 425.45it/s]\n",
      "  0%|          | 45/26993 [00:00<01:02, 428.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept: 17348 Our of: 40817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Kept: 50707 Our of: 122002\n"
     ]
    }
   ],
   "source": [
    "new_train = data_dir / data_subfolder / \"train_titlecue.jsonl\"\n",
    "new_dev = data_dir / data_subfolder / \"dev_titlecue.jsonl\" \n",
    "subsample_data(dev_file, new_dev)\n",
    "subsample_data(train_file, new_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out the same mention per doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samemention_data(orig, new):\n",
    "    num_al = []\n",
    "    new_sent_i = 0\n",
    "    with open(orig) as in_f, open(new, \"w\") as out_f:\n",
    "        for line in tqdm(in_f, total=sum(1 for _ in open(orig))):\n",
    "            line = json.loads(line)\n",
    "            alias_to_idx = defaultdict(list)\n",
    "            for al_i, al in enumerate(line[\"aliases\"]):\n",
    "                alias_to_idx[al].append(al_i)\n",
    "            for al in alias_to_idx:\n",
    "                new_line = {\n",
    "                    \"aliases\": [],\n",
    "                    \"qids\": [],\n",
    "                    \"spans\": [],\n",
    "                    \"gold\": [],\n",
    "                    \"sentence\": \"\",\n",
    "                    \"sent_idx_unq\": -1,\n",
    "                    \"doc_id\": -1\n",
    "                }\n",
    "                for al_i in alias_to_idx[al]:\n",
    "                    new_line[\"aliases\"].append(line[\"aliases\"][al_i])\n",
    "                    new_line[\"qids\"].append(line[\"qids\"][al_i])\n",
    "                    new_line[\"spans\"].append(line[\"spans\"][al_i])\n",
    "                    new_line[\"gold\"].append(line[\"gold\"][al_i])\n",
    "                    new_line[\"sentence\"] = line[\"sentence\"]\n",
    "                    new_line[\"doc_id\"] = line[\"doc_id\"]\n",
    "                    new_line[\"sent_idx_unq\"] = new_sent_i\n",
    "                    new_line[\"old_sent_idx_unq\"] = line[\"sent_idx_unq\"]\n",
    "                    new_sent_i += 1\n",
    "                num_al.append(len(new_line[\"aliases\"]))\n",
    "                out_f.write(json.dumps(new_line) + \"\\n\")\n",
    "    print(f\"Wrote out {new_sent_i} sentences\")\n",
    "    print(f\"Average Num Aliases per sent {np.mean(num_al)}. Percentile {np.percentile(num_al, 95)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:00<00:00, 2373.95it/s]\n",
      " 11%|█         | 286/2635 [00:00<00:00, 2857.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote out 40767 sentences\n",
      "Average Num Aliases per sent 1.6801434223541047. Percentile 5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2635/2635 [00:00<00:00, 3302.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote out 97843 sentences\n",
      "Average Num Aliases per sent 1.6727014736554175. Percentile 5.0\n"
     ]
    }
   ],
   "source": [
    "new_train = data_dir / data_subfolder / \"train_same_men.jsonl\"\n",
    "new_dev = data_dir / data_subfolder / \"dev_same_men.jsonl\" \n",
    "samemention_data(dev_file, new_dev)\n",
    "samemention_data(train_file, new_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at type discriminativeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_discrim(df):\n",
    "    num_cands = []\n",
    "    num_share_type = []\n",
    "    for i, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        cand_qids = row[\"cand_qids\"]\n",
    "        cand_types = [types_s.get_types(q) for q in cand_qids]\n",
    "        gold_types = set(types_s.get_types(row[\"gold_qid\"]))\n",
    "        c = 0\n",
    "        for c_t in cand_types:\n",
    "            if len(gold_types.intersection(c_t)) > 0:\n",
    "                c += 1\n",
    "        num_cands.append(len(cand_qids))\n",
    "        num_share_type.append(c)\n",
    "    return num_cands, num_share_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99912/99912 [00:16<00:00, 6014.49it/s]\n"
     ]
    }
   ],
   "source": [
    "num_c, num_t = type_discrim(train_df)\n",
    "num_c = np.array(num_c)\n",
    "num_t = np.array(num_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 30 17.48769917527424 17.0 25.0\n",
      "1 28 6.362278805348707 6.0 12.0\n"
     ]
    }
   ],
   "source": [
    "print(num_c.min(), num_c.max(), num_c.mean(), np.percentile(num_c, 50), np.percentile(num_c, 90))\n",
    "print(num_t.min(), num_t.max(), num_t.mean(), np.percentile(num_t, 50), np.percentile(num_t, 90))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
