{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Embedding Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we walk through how to generate Bootleg contextual entity embeddings for use in downstream tasks using a pretrained Bootleg model. We also demonstrate how to extract Bootleg's static learned embeddings for downstream tasks when contextualized embeddings are not needed.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "You will need to download the following files for this notebook:\n",
    "- The sample of Natural Questions with hand-labelled entities [here](https://bootleg-emb.s3.amazonaws.com/data/nq.tar.gz)\n",
    "- Entity profile information [here](https://bootleg-emb.s3.amazonaws.com/entity_db.tar.gz)\n",
    "- Pretrained Bootleg model and config [here](https://bootleg-emb.s3.amazonaws.com/models/2020_08_25/bootleg_wiki.tar.gz)\n",
    "- Embedding data [here](https://bootleg-emb.s3.amazonaws.com/emb_data.tar.gz)\n",
    "\n",
    "These are the same files as the End-to-End tutorial and do not need to be re-downloaded if you completed that tutorial. \n",
    "\n",
    "For convenience, you can run the command below (from the `tutorials` directory) to download all the above files and unpack them to the provided directory. It will take several minutes to download all the files. \n",
    "\n",
    "    bash download_all.sh <NAME_OF_DIRECTORY_TO_SAVE_DATA>\n",
    "    \n",
    "You will need to assign the variable `input_dir` in this notebook to the path where you download the data.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Prepare Model Config\n",
    "\n",
    "As with the other tutorials, we set up the config to point to the correct data directories and model checkpoint. We use the sample of [Natural Questions](https://ai.google.com/research/NaturalQuestions) with mentions extracted by Bootleg introduced in the End-to-End tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import ujson\n",
    "from utils import load_mentions, tagme_annotate\n",
    "\n",
    "from bootleg import run\n",
    "from bootleg.utils.parser_utils import get_full_config\n",
    "\n",
    "# set up logging\n",
    "import sys\n",
    "import logging\n",
    "from importlib import reload\n",
    "reload(logging)\n",
    "logging.basicConfig(stream=sys.stdout, format='%(asctime)s %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not have a GPU with at least 12GB of memory available, set the below to `True` to run inference on the CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cpu = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify the input directory where files were downloaded below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = # FILL IN WITH FULL PATH TO DATA DIRECTORY WHERE FILES ARE DOWNLOADED\n",
    "\n",
    "config_path = f'{input_dir}/bootleg_wiki/bootleg_config.json'\n",
    "config_args = get_full_config(config_path)\n",
    "\n",
    "# set the model checkpoint path \n",
    "config_args.run_config.init_checkpoint = f'{input_dir}/bootleg_wiki/bootleg_model.pt'\n",
    "\n",
    "# set the path for the entity db and candidate map\n",
    "config_args.data_config.entity_dir = f'{input_dir}/entity_db'\n",
    "config_args.data_config.alias_cand_map = 'alias2qids_wiki.json'\n",
    "\n",
    "# set the data path and RSS500 test file \n",
    "config_args.data_config.data_dir = f'{input_dir}/nq'\n",
    "\n",
    "# to speed things up for the tutorial, we have already prepped the data with the mentions detected by Bootleg\n",
    "config_args.data_config.test_dataset.file = 'test_natural_questions_50_bootleg.jsonl'\n",
    "\n",
    "# set the embedding paths \n",
    "config_args.data_config.emb_dir =  f'{input_dir}/emb_data'\n",
    "config_args.data_config.word_embedding.cache_dir =  f'{input_dir}/emb_data'\n",
    "\n",
    "# set the save directory \n",
    "config_args.run_config.save_dir = f'{input_dir}/results'\n",
    "\n",
    "# set whether to run inference on the CPU\n",
    "config_args.run_config.cpu = use_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Contextual Entity Embeddings\n",
    "\n",
    "We now show how Bootleg contextualized embeddings can be loaded and used in downstream tasks. First we use the `dump_embs` mode to generate contextual entity embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-09 13:09:37,243 PyTorch version 1.5.0 available.\n",
      "2020-09-09 13:09:38,540 Loading entity_symbols...\n",
      "2020-09-09 13:10:24,499 Loaded entity_symbols with 5222808 entities.\n",
      "2020-09-09 13:10:24,505 Loading slices...\n",
      "2020-09-09 13:10:24,507 Finished loading slices.\n",
      "2020-09-09 13:10:24,509 Loading dataset...\n",
      "2020-09-09 13:10:24,512 Finished loading dataset.\n",
      "2020-09-09 13:10:38,605 Sampled 50 indices from dataset (dev/test) for evaluation.\n",
      "2020-09-09 13:10:38,824 Loading embeddings...\n",
      "2020-09-09 13:11:01,853 Finished loading embeddings.\n",
      "2020-09-09 13:11:01,901 Loading model from data/bootleg_wiki/bootleg_model.pt...\n",
      "2020-09-09 13:11:04,343 Successfully loaded model from data/bootleg_wiki/bootleg_model.pt starting from checkpoint epoch 2 and step 0.\n",
      "2020-09-09 13:11:04,360 ************************DUMPING PREDICTIONS FOR test_natural_questions_50_bootleg.jsonl************************\n",
      "2020-09-09 13:11:04,490 64 samples, 2 batches\n",
      "2020-09-09 13:11:09,572 Writing predictions...\n",
      "2020-09-09 13:11:09,576 Total number of mentions across all sentences: 100\n",
      "2020-09-09 13:11:09,634 Finished writing predictions to data/results/20200909_130937/test_natural_questions_50_bootleg/eval/bootleg_model/bootleg_labels.jsonl\n",
      "2020-09-09 13:11:09,713 Saving contextual entity embeddings to data/results/20200909_130937/test_natural_questions_50_bootleg/eval/bootleg_model/bootleg_embs.npy\n"
     ]
    }
   ],
   "source": [
    "bootleg_label_file, bootleg_emb_file = run.model_eval(args=config_args, mode=\"dump_embs\", logger=logger, is_writer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `dump_embs` mode, Bootleg saves the contextual entity embeddings corresponding to each mention in each sentence to a file. We return this file in the variable `bootleg_emb_file`. We can also see the full file path in the log (ends in `*npy`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 350)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "contextual_entity_embs = np.load(bootleg_emb_file)\n",
    "contextual_entity_embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the contextual entity embedding above corresponds to an extracted mention in a sentence. In the above embedding there are 100 extracted mentions total with 350 dimensions for each corresponding contextual entity embedding.\n",
    "\n",
    "The mapping from mentions to rows in the contextual entity embedding is stored in `ctx_emb_ids` in the label file. We now check out the label file, which was also generated and returned from running `dump_embs` mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: who did the voice of the magician in frosty the snowman\n",
      "mentions: ['the voice', 'the magician', 'frosty the snowman']\n",
      "contextual emb ids: [0, 1, 2]\n",
      "\n",
      "sentence: what is considered the outer banks in north carolina\n",
      "mentions: ['outer banks', 'north carolina']\n",
      "contextual emb ids: [3, 4]\n",
      "\n",
      "sentence: the nashville sound brought a polished and cosmopolitan sound to country music by\n",
      "mentions: ['the nashville sound', 'cosmopolitan', 'country music']\n",
      "contextual emb ids: [5, 6, 7]\n",
      "\n",
      "sentence: what channel is the premier league on in france\n",
      "mentions: ['premier league', 'france']\n",
      "contextual emb ids: [8, 9]\n",
      "\n",
      "sentence: i love it ( feat . charli xcx ) icona pop\n",
      "mentions: ['i love it', 'charli xcx', 'icona pop']\n",
      "contextual emb ids: [10, 11, 12]\n",
      "\n",
      "sentence: the u.s. supreme court hears appeals from circuit courts\n",
      "mentions: ['us supreme court', 'circuit courts']\n",
      "contextual emb ids: [13, 14]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "with jsonlines.open(bootleg_label_file) as f: \n",
    "    for i, line in enumerate(f): \n",
    "        print('sentence:', line['sentence'])\n",
    "        print('mentions:', line['aliases'])\n",
    "        print('contextual emb ids:', line['ctx_emb_ids'])\n",
    "        print()\n",
    "        if i == 5: \n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first sentence, we can find the corresponding contextual entity embedding for \"the voice\", \"the magician\", and \"frosty the snowman\" in rows 0, 1, and 2 of `contextual_entity_embs`, respectively. Similarly, we have unique row ids for the mentions in each of the other sentences. A downstream task can use this process to load the correct contextual entity embeddings for each mention in a simple dataloader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Static Entity Embeddings\n",
    "\n",
    "In addition to contextual entity embeddings, Bootleg learns static entity embeddings. These can be useful in downstream tasks when contextual information is not available for the downstream task, or if we want the same entity embedding regardless of the context or position of the mention.\n",
    "\n",
    "We walk through how to extract the static, learned entity embeddings from a pretrained Bootleg model. First, we define a utility function to load a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch \n",
    "\n",
    "from bootleg.model import Model\n",
    "from bootleg.symbols.entity_symbols import EntitySymbols\n",
    "from bootleg.utils import data_utils\n",
    "\n",
    "def load_model(config_args, device='cuda', logger=None):\n",
    "    logger.info(f'Using device {device}')\n",
    "    entity_db =  EntitySymbols(os.path.join(config_args.data_config.entity_dir,\n",
    "                                                             config_args.data_config.entity_map_dir), \n",
    "                              alias_cand_map_file=config_args.data_config.alias_cand_map)\n",
    "    word_db = data_utils.load_wordsymbols(config_args.data_config, is_writer=True, distributed=False)\n",
    "\n",
    "    model = Model(args=config_args, model_device=device,\n",
    "            entity_symbols=entity_db, word_symbols=word_db).to(device)\n",
    "    \n",
    "    logger.info(f'Loading model from {config_args.run_config.init_checkpoint}.')\n",
    "    model_state_dict = torch.load(config_args.run_config.init_checkpoint,\n",
    "            map_location=lambda storage, loc: storage)['model']\n",
    "    logger.info('Loaded model.')\n",
    "    model.load_state_dict(model_state_dict, strict=True)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pretrained Bootleg model. This will take several minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-09 13:16:34,411 Using device cuda\n",
      "2020-09-09 13:17:40,255 Loading embeddings...\n",
      "2020-09-09 13:18:09,154 Finished loading embeddings.\n",
      "2020-09-09 13:18:12,417 Loading model from data/bootleg_wiki/bootleg_model.pt.\n",
      "2020-09-09 13:18:14,394 Loaded model.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(config_args, logger=logger, device='cuda' if not use_cpu else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the static, learned entity embedding as a torch tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5222810, 200])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_embedding = model.emb_layer.entity_embs.learned.learned_entity_embedding.weight.data \n",
    "ent_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Bootleg model was trained on data with 5.2 million entities and each entity embedding is 200-dimensional, as indicated by the shape of the static, learned entity embedding above.\n",
    "\n",
    "The mapping from mentions to rows in the static, learned entity embedding (corresponding to the predicted entity) is also saved in the label file produced by `dump_embs` mode. We check out the label file below and use the `entity_ids` key to find the corresponding embedding row.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: who did the voice of the magician in frosty the snowman\n",
      "mentions: ['the voice', 'the magician', 'frosty the snowman']\n",
      "entity ids: [3071527, 45732, 306516]\n",
      "\n",
      "sentence: what is considered the outer banks in north carolina\n",
      "mentions: ['outer banks', 'north carolina']\n",
      "entity ids: [647415, 9799]\n",
      "\n",
      "sentence: the nashville sound brought a polished and cosmopolitan sound to country music by\n",
      "mentions: ['the nashville sound', 'cosmopolitan', 'country music']\n",
      "entity ids: [4738654, 23349, 2164]\n",
      "\n",
      "sentence: what channel is the premier league on in france\n",
      "mentions: ['premier league', 'france']\n",
      "entity ids: [4919, 315399]\n",
      "\n",
      "sentence: i love it ( feat . charli xcx ) icona pop\n",
      "mentions: ['i love it', 'charli xcx', 'icona pop']\n",
      "entity ids: [3485924, 3363307, 3469283]\n",
      "\n",
      "sentence: the u.s. supreme court hears appeals from circuit courts\n",
      "mentions: ['us supreme court', 'circuit courts']\n",
      "entity ids: [14506, 30881]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "with jsonlines.open(bootleg_label_file) as f: \n",
    "    for i, line in enumerate(f): \n",
    "        print('sentence:', line['sentence'])\n",
    "        print('mentions:', line['aliases'])\n",
    "        print('entity ids:', line['entity_ids'])\n",
    "        print()\n",
    "        if i == 5: \n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the contextual entity embeddings, the static embeddings are not unique across mentions. For instance, if the same entity is predicted across two different mentions, the static entity embedding (and ids in the label file) will be the same for those mentions, whereas the contextual entity embeddings and ids will be different. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctx",
   "language": "python",
   "name": "ctx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
