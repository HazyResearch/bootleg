{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Embedding Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we walk through how to generate Bootleg contextual entity embeddings for use in downstream tasks using a pretrained Bootleg model. We also demonstrate how to extract Bootleg's static learned embeddings for downstream tasks when contextualized embeddings are not needed.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "You will need to download the following files for this notebook:\n",
    "- Pretrained Bootleg model and config [here](https://bootleg-emb.s3.amazonaws.com/models/2020_10_22/bootleg_wiki.tar.gz)\n",
    "- Sample of Natural Questions with hand-labelled entities [here](https://bootleg-emb.s3.amazonaws.com/data/nq.tar.gz)\n",
    "- Entity data [here](https://bootleg-emb.s3.amazonaws.com/data/wiki_entity_data.tar.gz)\n",
    "- Embedding data [here](https://bootleg-emb.s3.amazonaws.com/data/emb_data.tar.gz)\n",
    "- Pretrained BERT model [here](https://bootleg-emb.s3.amazonaws.com/pretrained_bert_models.tar.gz)\n",
    "\n",
    "These are the same files as the End-to-End tutorial and do not need to be re-downloaded if you completed that tutorial. \n",
    "\n",
    "For convenience, you can run the commands below (from the root directory of the repo) to download all the above files and unpack them to `models`, `data`, and `pretrained_bert_models` directories. It will take several minutes to download all the files. \n",
    "\n",
    "    bash download_model.sh \n",
    "    bash download_data.sh \n",
    "    bash download_bert.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Prepare Model Config\n",
    "\n",
    "As with the other tutorials, we set up the config to point to the correct data directories and model checkpoint. We use the sample of [Natural Questions](https://ai.google.com/research/NaturalQuestions) with mentions extracted by Bootleg introduced in the End-to-End tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/lorr1/my_env_dawn/lib/python3.6/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "/dfs/scratch0/lorr1/my_env_dawn/lib/python3.6/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import ujson\n",
    "from utils import load_mentions, tagme_annotate\n",
    "\n",
    "from bootleg import run\n",
    "from bootleg.utils.parser_utils import get_full_config\n",
    "\n",
    "# set up logging\n",
    "import sys\n",
    "import logging\n",
    "from importlib import reload\n",
    "reload(logging)\n",
    "logging.basicConfig(stream=sys.stdout, format='%(asctime)s %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a GPU with at least 12GB of memory available, set the below to `False` to run inference on a GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cpu = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify the input directory where files were downloaded below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = # FILL IN FULL PATH TO ROOT REPO DIRECTORY HERE\n",
    "config_path = f'{root_dir}/models/bootleg_wiki/bootleg_config.json'\n",
    "config_args = get_full_config(config_path)\n",
    "\n",
    "# decrease number of data threads as this is a small file\n",
    "config_args.data_config.dataset_threads = 2\n",
    "\n",
    "# set the model checkpoint path \n",
    "config_args.run_config.init_checkpoint = f'{root_dir}/models/bootleg_wiki/bootleg_model.pt'\n",
    "\n",
    "# set the path for the entity db and candidate map\n",
    "config_args.data_config.entity_dir = f'{root_dir}/data/wiki_entity_data'\n",
    "config_args.data_config.alias_cand_map = 'alias2qids_wiki.json'\n",
    "\n",
    "# set the data path and RSS500 test file \n",
    "config_args.data_config.data_dir = f'{root_dir}/data/nq'\n",
    "\n",
    "# to speed things up for the tutorial, we have already prepped the data with the mentions detected by Bootleg\n",
    "config_args.data_config.test_dataset.file = 'test_natural_questions_50_bootleg.jsonl'\n",
    "\n",
    "# set the embedding paths \n",
    "config_args.data_config.emb_dir =  f'{root_dir}/data/emb_data'\n",
    "config_args.data_config.word_embedding.cache_dir =  f'{root_dir}/pretrained_bert_models'\n",
    "\n",
    "# set the save directory \n",
    "config_args.run_config.save_dir = f'{root_dir}/results'\n",
    "\n",
    "# set whether to run inference on the CPU\n",
    "config_args.run_config.cpu = use_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Contextual Entity Embeddings\n",
    "\n",
    "We now show how Bootleg contextualized embeddings can be loaded and used in downstream tasks. First we use the `dump_embs` mode to generate contextual entity embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-21 18:11:21,769 PyTorch version 1.5.0 available.\n",
      "2020-10-21 18:11:24,719 TensorFlow version 2.2.0 available.\n",
      "2020-10-21 18:11:25,410 Loading entity_symbols...\n",
      "2020-10-21 18:12:11,442 Loaded entity_symbols with 5310039 entities.\n",
      "2020-10-21 18:12:12,237 Loading slices...\n",
      "2020-10-21 18:12:12,259 Finished loading slices.\n",
      "2020-10-21 18:12:32,381 Loading dataset...\n",
      "2020-10-21 18:12:32,412 Finished loading dataset.\n",
      "2020-10-21 18:12:37,468 Loading embeddings...\n",
      "2020-10-21 18:13:01,797 Finished loading embeddings.\n",
      "2020-10-21 18:13:01,886 Loading model from /dfs/scratch0/lorr1/bootleg/bootleg-internal/new_tutorial_data/models/bootleg_wiki/bootleg_model.pt...\n",
      "2020-10-21 18:13:10,063 Successfully loaded model from /dfs/scratch0/lorr1/bootleg/bootleg-internal/new_tutorial_data/models/bootleg_wiki/bootleg_model.pt starting from checkpoint epoch 1 and step 0.\n",
      "2020-10-21 18:13:10,128 ************************DUMPING PREDICTIONS FOR test_natural_questions_50_bootleg.jsonl************************\n",
      "2020-10-21 18:13:10,270 64 samples, 4 batches, 50 len dataset\n",
      "2020-10-21 18:13:16,221 Writing predictions to /dfs/scratch0/lorr1/bootleg/bootleg-internal/new_tutorial_data/results/20200914_104853/test_natural_questions_50_bootleg/eval/bootleg_model/bootleg_labels.jsonl...\n",
      "2020-10-21 18:13:16,225 Total number of mentions across all sentences: 104\n",
      "2020-10-21 18:13:16,286 Finished writing predictions to /dfs/scratch0/lorr1/bootleg/bootleg-internal/new_tutorial_data/results/20200914_104853/test_natural_questions_50_bootleg/eval/bootleg_model/bootleg_labels.jsonl\n",
      "2020-10-21 18:13:16,339 Saving contextual entity embeddings to /dfs/scratch0/lorr1/bootleg/bootleg-internal/new_tutorial_data/results/20200914_104853/test_natural_questions_50_bootleg/eval/bootleg_model/bootleg_embs.npy\n",
      "2020-10-21 18:13:16,340 Wrote predictions to /dfs/scratch0/lorr1/bootleg/bootleg-internal/new_tutorial_data/results/20200914_104853/test_natural_questions_50_bootleg/eval/bootleg_model/bootleg_labels.jsonl\n"
     ]
    }
   ],
   "source": [
    "bootleg_label_file, bootleg_emb_file = run.model_eval(args=config_args, mode=\"dump_embs\", logger=logger, is_writer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `dump_embs` mode, Bootleg saves the contextual entity embeddings corresponding to each mention in each sentence to a file. We return this file in the variable `bootleg_emb_file`. We can also see the full file path in the log (ends in `*npy`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 512)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "contextual_entity_embs = np.load(bootleg_emb_file)\n",
    "contextual_entity_embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the contextual entity embedding above corresponds to an extracted mention in a sentence. In the above embedding there are 100 extracted mentions total with 350 dimensions for each corresponding contextual entity embedding.\n",
    "\n",
    "The mapping from mentions to rows in the contextual entity embedding is stored in `ctx_emb_ids` in the label file. We now check out the label file, which was also generated and returned from running `dump_embs` mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: who did the voice of the magician in frosty the snowman\n",
      "mentions: ['the voice', 'the magician', 'frosty the snowman']\n",
      "contextual emb ids: [0, 1, 2]\n",
      "\n",
      "sentence: what is considered the outer banks in north carolina\n",
      "mentions: ['outer banks', 'north carolina']\n",
      "contextual emb ids: [3, 4]\n",
      "\n",
      "sentence: the nashville sound brought a polished and cosmopolitan sound to country music by\n",
      "mentions: ['the nashville sound', 'cosmopolitan', 'country music']\n",
      "contextual emb ids: [5, 6, 7]\n",
      "\n",
      "sentence: what channel is the premier league on in france\n",
      "mentions: ['premier league', 'france']\n",
      "contextual emb ids: [8, 9]\n",
      "\n",
      "sentence: i love it ( feat . charli xcx ) icona pop\n",
      "mentions: ['i love it', 'charli xcx', 'icona pop']\n",
      "contextual emb ids: [10, 11, 12]\n",
      "\n",
      "sentence: the u.s. supreme court hears appeals from circuit courts\n",
      "mentions: ['us supreme court', 'circuit courts']\n",
      "contextual emb ids: [13, 14]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "with jsonlines.open(bootleg_label_file) as f: \n",
    "    for i, line in enumerate(f): \n",
    "        print('sentence:', line['sentence'])\n",
    "        print('mentions:', line['aliases'])\n",
    "        print('contextual emb ids:', line['ctx_emb_ids'])\n",
    "        print()\n",
    "        if i == 5: \n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first sentence, we can find the corresponding contextual entity embedding for \"the voice\", \"the magician\", and \"frosty the snowman\" in rows 0, 1, and 2 of `contextual_entity_embs`, respectively. Similarly, we have unique row ids for the mentions in each of the other sentences. A downstream task can use this process to load the correct contextual entity embeddings for each mention in a simple dataloader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Static Entity Embeddings\n",
    "\n",
    "In addition to contextual entity embeddings, Bootleg learns static entity embeddings. These can be useful in downstream tasks when contextual information is not available for the downstream task, or if we want the same entity embedding regardless of the context or position of the mention.\n",
    "\n",
    "We walk through how to extract the static, learned entity embeddings from a pretrained Bootleg model. First, we define a utility function to load a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch \n",
    "from collections import OrderedDict\n",
    "\n",
    "from bootleg.model import Model\n",
    "from bootleg.symbols.entity_symbols import EntitySymbols\n",
    "from bootleg.utils import data_utils\n",
    "\n",
    "def load_model(config_args, device='cuda', logger=None):\n",
    "    logger.info(f'Using device {device}')\n",
    "    entity_db =  EntitySymbols(os.path.join(config_args.data_config.entity_dir,\n",
    "                                                             config_args.data_config.entity_map_dir), \n",
    "                              alias_cand_map_file=config_args.data_config.alias_cand_map)\n",
    "    word_db = data_utils.load_wordsymbols(config_args.data_config, is_writer=True, distributed=False)\n",
    "\n",
    "    model = Model(args=config_args, model_device=device,\n",
    "            entity_symbols=entity_db, word_symbols=word_db).to(device)\n",
    "    \n",
    "    logger.info(f'Loading model from {config_args.run_config.init_checkpoint}.')\n",
    "    model_state_dict = torch.load(config_args.run_config.init_checkpoint,\n",
    "            map_location=lambda storage, loc: storage)['model']\n",
    "    logger.info('Loaded model.')\n",
    "    if config_args.run_config.distributed:\n",
    "        # Remove distributed naming if model trained in distributed mode\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in model_state_dict.items():\n",
    "            if k.startswith('module.'):\n",
    "                name = k[len('module.'):]\n",
    "                new_state_dict[name] = v\n",
    "            else:\n",
    "                new_state_dict[k] = v\n",
    "        model_state_dict = new_state_dict\n",
    "    model.load_state_dict(model_state_dict, strict=True)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pretrained Bootleg model. This will take several minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-21 18:20:56,809 Using device cpu\n",
      "2020-10-21 18:22:27,588 Loading embeddings...\n",
      "2020-10-21 18:22:52,005 Finished loading embeddings.\n",
      "2020-10-21 18:22:52,098 Loading model from /dfs/scratch0/lorr1/bootleg/bootleg-internal/new_tutorial_data/models/bootleg_wiki/bootleg_model.pt.\n",
      "2020-10-21 18:22:59,825 Loaded model.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(config_args, logger=logger, device='cuda' if not use_cpu else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the static, learned entity embedding as a torch tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5310041, 256])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_embedding = model.emb_layer.entity_embs.learned.learned_entity_embedding.weight.data \n",
    "ent_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Bootleg model was trained on data with 5.2 million entities and each entity embedding is 200-dimensional, as indicated by the shape of the static, learned entity embedding above.\n",
    "\n",
    "The mapping from mentions to rows in the static, learned entity embedding (corresponding to the predicted entity) is also saved in the label file produced by `dump_embs` mode. We check out the label file below and use the `entity_ids` key to find the corresponding embedding row.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: who did the voice of the magician in frosty the snowman\n",
      "mentions: ['the voice', 'the magician', 'frosty the snowman']\n",
      "entity ids: [3137025, 47084, 317160]\n",
      "\n",
      "sentence: what is considered the outer banks in north carolina\n",
      "mentions: ['outer banks', 'north carolina']\n",
      "entity ids: [669293, 10038]\n",
      "\n",
      "sentence: the nashville sound brought a polished and cosmopolitan sound to country music by\n",
      "mentions: ['the nashville sound', 'cosmopolitan', 'country music']\n",
      "entity ids: [4820686, 23951, 2213]\n",
      "\n",
      "sentence: what channel is the premier league on in france\n",
      "mentions: ['premier league', 'france']\n",
      "entity ids: [5048, 1039794]\n",
      "\n",
      "sentence: i love it ( feat . charli xcx ) icona pop\n",
      "mentions: ['i love it', 'charli xcx', 'icona pop']\n",
      "entity ids: [3556241, 3432476, 3539431]\n",
      "\n",
      "sentence: the u.s. supreme court hears appeals from circuit courts\n",
      "mentions: ['us supreme court', 'circuit courts']\n",
      "entity ids: [14865, 31738]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "with jsonlines.open(bootleg_label_file) as f: \n",
    "    for i, line in enumerate(f): \n",
    "        print('sentence:', line['sentence'])\n",
    "        print('mentions:', line['aliases'])\n",
    "        print('entity ids:', line['entity_ids'])\n",
    "        print()\n",
    "        if i == 5: \n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the contextual entity embeddings, the static embeddings are not unique across mentions. For instance, if the same entity is predicted across two different mentions, the static entity embedding (and ids in the label file) will be the same for those mentions, whereas the contextual entity embeddings and ids will be different. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
