{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End NED Tutorial\n",
    "\n",
    "In this tutorial, we walk through how to use Bootleg as an end-to-end pipeline to detect and label entities in a set of sentences. First, we show how to use Bootleg to detect and disambiguate mentions to entities. We then compare to an existing system named TAGME. Finally, we show how to use Bootleg to annotate individual sentences on the fly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand how Bootleg performs on more natural language than we find in Wikipedia, we hand label the mentions and corresponding entities in 50 questions sampled from the [Natural Questions dataset (Google)](https://ai.google.com/research/NaturalQuestions). \n",
    "\n",
    "### Requirements\n",
    "\n",
    "You will need to download the following files for this notebook:\n",
    "- Pretrained Bootleg model and config [here](https://bootleg-emb.s3.amazonaws.com/models/2020_12_09/bootleg_wiki.tar.gz)*\n",
    "- Sample of Natural Questions with hand-labelled entities [here](https://bootleg-emb.s3.amazonaws.com/data/nq.tar.gz)\n",
    "- Entity data [here](https://bootleg-emb.s3.amazonaws.com/data/wiki_entity_data.tar.gz)*\n",
    "- Embedding data [here](https://bootleg-emb.s3.amazonaws.com/data/emb_data.tar.gz)*\n",
    "- Pretrained BERT model [here](https://bootleg-emb.s3.amazonaws.com/pretrained_bert_models.tar.gz)*\n",
    "\n",
    "*Same file as in benchmark tutorial and does not need to be re-downloaded.\n",
    "\n",
    "For convenience, you can run the commands below (from the root directory of the repo) to download all the above files and unpack them to `models`, `data`, and `pretrained_bert_models` directories. It will take several minutes to download all the files. \n",
    "\n",
    "    bash download_model.sh \n",
    "    bash download_data.sh \n",
    "    bash download_bert.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import ujson\n",
    "from utils import load_mentions, tagme_annotate\n",
    "\n",
    "# set up logging\n",
    "import sys\n",
    "import logging\n",
    "from importlib import reload\n",
    "reload(logging)\n",
    "logging.basicConfig(stream=sys.stdout, format='%(asctime)s %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "root_dir = \"\" \n",
    "cand_map = f'{root_dir}/data/wiki_entity_data/entity_mappings/alias2qids_wiki.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a GPU with at least 12GB of memory available, set the below to `False` to run inference on a GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cpu = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Detect Mentions\n",
    "Bootleg uses a simple mention extraction algorithm that extracts mentions using a given candidate map. We will use a Wikipedia candidate map that we mined using Wikipedia anchor links and Wikidata aliases for a total of ~8 million mentions (provided in the Requirements section of this notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the input dataset for the end-to-end pipeline, we assume a jsonlines file with a single dictionary with the key \"sentence\" and value as the text of the sentence, per line. For instance, you may have a file with the lines:\n",
    "\n",
    "    {\"sentence\": \"who did the voice of the magician in frosty the snowman\"}\n",
    "    {\"sentence\": \"what is considered the outer banks in north carolina\"}\n",
    "    \n",
    "Below, we have additional keys to keep track of the hand-labelled mentions, but this is purely for evaluating the quality of the end-to-end pipeline and is not needed in the common use cases of using Bootleg to detect and label mentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_sample_orig = f'{root_dir}/data/nq/test_natural_questions_50.jsonl'\n",
    "nq_sample_bootleg = f'{root_dir}/data/nq/test_natural_questions_50_bootleg.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-18 00:20:05,534 Loading candidate mapping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8002525/8002525 [00:16<00:00, 485888.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-18 00:20:22,008 Loaded candidate mapping with 8002525 aliases.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-18 00:20:35,476 Using 8 workers...\n",
      "2020-12-18 00:20:35,477 Reading in /dfs/scratch0/lorr1/bootleg/bootleg-internal/tutorial_data/data/nq/test_natural_questions_50.jsonl\n",
      "2020-12-18 00:20:35,771 Wrote out data chunks in 0.29s\n",
      "2020-12-18 00:20:35,772 Calling subprocess...\n",
      "2020-12-18 00:20:37,162 Merging files...\n",
      "2020-12-18 00:20:37,210 Removing temporary files...\n",
      "2020-12-18 00:20:37,394 Finished in 1.9379315376281738 seconds. Wrote out to /dfs/scratch0/lorr1/bootleg/bootleg-internal/tutorial_data/data/nq/test_natural_questions_50_bootleg.jsonl\n"
     ]
    }
   ],
   "source": [
    "from bootleg.extract_mentions import extract_mentions\n",
    "extract_mentions(in_filepath=nq_sample_orig, out_filepath=nq_sample_bootleg, cand_map_file=cand_map, logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at a sample of the extracted mentions, we can compare the mention extraction phase to the hand-labelled mentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>aliases_hand</th>\n",
       "      <th>spans_hand</th>\n",
       "      <th>aliases_bootleg</th>\n",
       "      <th>spans_bootleg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the u.s. supreme court hears appeals from circuit courts</td>\n",
       "      <td>[u.s. supreme court, circuit courts]</td>\n",
       "      <td>[[1, 4], [7, 9]]</td>\n",
       "      <td>[us supreme court, circuit courts]</td>\n",
       "      <td>[[1, 4], [7, 9]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the nashville sound brought a polished and cosmopolitan sound to country music by</td>\n",
       "      <td>[nashville sound, country music]</td>\n",
       "      <td>[[1, 3], [10, 12]]</td>\n",
       "      <td>[the nashville sound, cosmopolitan]</td>\n",
       "      <td>[[0, 3], [7, 8]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>what is the worth of the catholic church</td>\n",
       "      <td>[catholic church]</td>\n",
       "      <td>[[6, 8]]</td>\n",
       "      <td>[catholic church]</td>\n",
       "      <td>[[6, 8]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>where is israel located on the world map</td>\n",
       "      <td>[israel, world map]</td>\n",
       "      <td>[[2, 3], [6, 8]]</td>\n",
       "      <td>[israel]</td>\n",
       "      <td>[[2, 3]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>who plays norman bates in the tv show</td>\n",
       "      <td>[norman bates]</td>\n",
       "      <td>[[2, 4]]</td>\n",
       "      <td>[norman bates]</td>\n",
       "      <td>[[2, 4]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>what was dennis hopper 's bike in easy rider</td>\n",
       "      <td>[dennis hopper, easy rider]</td>\n",
       "      <td>[[2, 4], [7, 9]]</td>\n",
       "      <td>[dennis hopper, easy rider]</td>\n",
       "      <td>[[2, 4], [7, 9]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>who played the bank robber in dirty harry</td>\n",
       "      <td>[dirty harry]</td>\n",
       "      <td>[[6, 8]]</td>\n",
       "      <td>[dirty harry]</td>\n",
       "      <td>[[6, 8]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>the pair of hand drums used in indian classical music is called</td>\n",
       "      <td>[indian classical music]</td>\n",
       "      <td>[[7, 10]]</td>\n",
       "      <td>[indian classical music]</td>\n",
       "      <td>[[7, 10]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>landmark supreme court cases dealing with the first amendment</td>\n",
       "      <td>[supreme court, first amendment]</td>\n",
       "      <td>[[1, 3], [7, 9]]</td>\n",
       "      <td>[supreme court, first amendment]</td>\n",
       "      <td>[[1, 3], [7, 9]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>what was the japanese motivation for bombing pearl harbor</td>\n",
       "      <td>[japanese, pearl harbor]</td>\n",
       "      <td>[[3, 4], [7, 9]]</td>\n",
       "      <td>[pearl harbor]</td>\n",
       "      <td>[[7, 9]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>what causes a dead zone in the ocean</td>\n",
       "      <td>[dead zone]</td>\n",
       "      <td>[[3, 5]]</td>\n",
       "      <td>[dead zone]</td>\n",
       "      <td>[[3, 5]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>when was the first freeway built in los angeles</td>\n",
       "      <td>[los angeles]</td>\n",
       "      <td>[[7, 9]]</td>\n",
       "      <td>[los angeles]</td>\n",
       "      <td>[[7, 9]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is considered the outer banks in north carolina</td>\n",
       "      <td>[outer banks, north carolina]</td>\n",
       "      <td>[[4, 6], [7, 9]]</td>\n",
       "      <td>[outer banks, north carolina]</td>\n",
       "      <td>[[4, 6], [7, 9]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>who plays claire underwood 's mom on house of cards</td>\n",
       "      <td>[claire underwood, house of cards]</td>\n",
       "      <td>[[2, 4], [7, 10]]</td>\n",
       "      <td>[claire underwood, house of cards]</td>\n",
       "      <td>[[2, 4], [7, 10]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>which of these was not an export of ancient greece</td>\n",
       "      <td>[ancient greece]</td>\n",
       "      <td>[[8, 10]]</td>\n",
       "      <td>[ancient greece]</td>\n",
       "      <td>[[8, 10]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             sentence  \\\n",
       "5                            the u.s. supreme court hears appeals from circuit courts   \n",
       "2   the nashville sound brought a polished and cosmopolitan sound to country music by   \n",
       "20                                           what is the worth of the catholic church   \n",
       "23                                           where is israel located on the world map   \n",
       "10                                              who plays norman bates in the tv show   \n",
       "12                                       what was dennis hopper 's bike in easy rider   \n",
       "19                                          who played the bank robber in dirty harry   \n",
       "21                    the pair of hand drums used in indian classical music is called   \n",
       "37                      landmark supreme court cases dealing with the first amendment   \n",
       "48                          what was the japanese motivation for bombing pearl harbor   \n",
       "28                                               what causes a dead zone in the ocean   \n",
       "36                                    when was the first freeway built in los angeles   \n",
       "1                                what is considered the outer banks in north carolina   \n",
       "29                                who plays claire underwood 's mom on house of cards   \n",
       "25                                 which of these was not an export of ancient greece   \n",
       "\n",
       "                            aliases_hand          spans_hand  \\\n",
       "5   [u.s. supreme court, circuit courts]    [[1, 4], [7, 9]]   \n",
       "2       [nashville sound, country music]  [[1, 3], [10, 12]]   \n",
       "20                     [catholic church]            [[6, 8]]   \n",
       "23                   [israel, world map]    [[2, 3], [6, 8]]   \n",
       "10                        [norman bates]            [[2, 4]]   \n",
       "12           [dennis hopper, easy rider]    [[2, 4], [7, 9]]   \n",
       "19                         [dirty harry]            [[6, 8]]   \n",
       "21              [indian classical music]           [[7, 10]]   \n",
       "37      [supreme court, first amendment]    [[1, 3], [7, 9]]   \n",
       "48              [japanese, pearl harbor]    [[3, 4], [7, 9]]   \n",
       "28                           [dead zone]            [[3, 5]]   \n",
       "36                         [los angeles]            [[7, 9]]   \n",
       "1          [outer banks, north carolina]    [[4, 6], [7, 9]]   \n",
       "29    [claire underwood, house of cards]   [[2, 4], [7, 10]]   \n",
       "25                      [ancient greece]           [[8, 10]]   \n",
       "\n",
       "                        aliases_bootleg      spans_bootleg  \n",
       "5    [us supreme court, circuit courts]   [[1, 4], [7, 9]]  \n",
       "2   [the nashville sound, cosmopolitan]   [[0, 3], [7, 8]]  \n",
       "20                    [catholic church]           [[6, 8]]  \n",
       "23                             [israel]           [[2, 3]]  \n",
       "10                       [norman bates]           [[2, 4]]  \n",
       "12          [dennis hopper, easy rider]   [[2, 4], [7, 9]]  \n",
       "19                        [dirty harry]           [[6, 8]]  \n",
       "21             [indian classical music]          [[7, 10]]  \n",
       "37     [supreme court, first amendment]   [[1, 3], [7, 9]]  \n",
       "48                       [pearl harbor]           [[7, 9]]  \n",
       "28                          [dead zone]           [[3, 5]]  \n",
       "36                        [los angeles]           [[7, 9]]  \n",
       "1         [outer banks, north carolina]   [[4, 6], [7, 9]]  \n",
       "29   [claire underwood, house of cards]  [[2, 4], [7, 10]]  \n",
       "25                     [ancient greece]          [[8, 10]]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_mentions_df = load_mentions(nq_sample_orig)\n",
    "bootleg_mentions_df = load_mentions(nq_sample_bootleg)\n",
    "\n",
    "# join dataframes and sample\n",
    "pd.merge(orig_mentions_df, bootleg_mentions_df, on=['sentence'], suffixes=['_hand', '_bootleg']).sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sample above, we see that generally Bootleg detects the same mentions as the hand-labelled mentions. However, sometimes Bootleg extracts extra mentions or fewer mentions. This is expected as Bootleg's mention extractor finds all mentions and then filters based on some simple heuristics if the mention is an entity or not. It will be the job of the backbone model and postprocessing to filter out any extra mentions by either thresholding the prediction probability or predicting a candidate that represents \"No Candidate\" (we refer to this as \"NC\").  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Disambiguate Mentions to Entities\n",
    "\n",
    "We run inference using a pretrained Bootleg model to disambiguate the extracted mentions to Wikidata QIDs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the model config so we can set additional parameters and load the saved model during evaluation. We need to update the config parameters to point to the downloaded model checkpoint and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bootleg import run\n",
    "from bootleg.utils.parser_utils import get_full_config\n",
    "\n",
    "config_path = f'{root_dir}/models/bootleg_wiki/bootleg_config.json'\n",
    "config_args = get_full_config(config_path)\n",
    "\n",
    "# decrease number of data threads as this is a small file\n",
    "config_args.run_config.dataset_threads = 2\n",
    "\n",
    "# set the model checkpoint path \n",
    "config_args.run_config.init_checkpoint = f'{root_dir}/models/bootleg_wiki/bootleg_model.pt'\n",
    "\n",
    "# set the path for the entity db and candidate map\n",
    "config_args.data_config.entity_dir = f'{root_dir}/data/wiki_entity_data'\n",
    "config_args.data_config.alias_cand_map = 'alias2qids_wiki.json'\n",
    "\n",
    "# set the data path and RSS500 test file \n",
    "config_args.data_config.data_dir = f'{root_dir}/data/nq'\n",
    "\n",
    "# to speed things up for the tutorial, we have already prepped the data with the mentions detected by Bootleg\n",
    "config_args.data_config.test_dataset.file = 'test_natural_questions_50_bootleg.jsonl'\n",
    "\n",
    "# set the embedding paths \n",
    "config_args.data_config.emb_dir =  f'{root_dir}/data/emb_data'\n",
    "config_args.data_config.word_embedding.cache_dir =  f'{root_dir}/pretrained_bert_models'\n",
    "\n",
    "# set the save directory \n",
    "config_args.run_config.save_dir = f'{root_dir}/results'\n",
    "\n",
    "# set whether to run inference on the CPU\n",
    "config_args.run_config.cpu = use_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run evaluation in `dump_embs` mode to dump predictions and contextualized entity embeddings. Note that this command is about 10 times slower using a notebook than on the command line. To speed up the next command, run the following on the command line first. Then come back and run the next cell.\n",
    "\n",
    "```\n",
    "python3 -m bootleg.run --mode dump_embs \\\n",
    "    --config_script <root_dir>/models/bootleg_wiki/bootleg_config.json \\\n",
    "    --run_config.dataset_threads 2 \\\n",
    "    --run_config.init_checkpoint <root_dir>/models/bootleg_wiki/bootleg_model.pt \\\n",
    "    --data_config.entity_dir <root_dir>/data/wiki_entity_data \\\n",
    "    --data_config.alias_cand_map alias2qids_wiki.json \\\n",
    "    --data_config.data_dir <root_dir>/data/nq \\\n",
    "    --data_config.test_dataset.file test_natural_questions_50_bootleg.jsonl \\\n",
    "    --data_config.emb_dir <root_dir>/data/emb_data \\\n",
    "    --data_config.word_embedding.cache_dir <root_dir>/pretrained_bert_models \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-18 00:20:38,123 Loading entity_symbols...\n",
      "2020-12-18 00:21:26,749 Loaded entity_symbols with 5310039 entities.\n",
      "2020-12-18 00:21:28,078 Loading slices...\n",
      "2020-12-18 00:22:47,182 Finished loading slices.\n",
      "2020-12-18 00:23:07,719 Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building alias table: 100%|██████████| 8002525/8002525 [07:59<00:00, 16705.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-18 00:36:07,234 Finished loading dataset.\n",
      "2020-12-18 00:36:11,548 Loading embeddings...\n",
      "2020-12-18 00:36:35,719 Finished loading embeddings.\n",
      "2020-12-18 00:36:35,816 Loading model from /dfs/scratch0/lorr1/bootleg/bootleg-internal/tutorial_data/models/bootleg_wiki/bootleg_model.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/lorr1/env_dawn_py36/lib/python3.6/site-packages/torch/nn/modules/container.py:550: UserWarning: Setting attributes on ParameterDict is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterDict is not supported.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-18 00:36:42,367 Successfully loaded model from /dfs/scratch0/lorr1/bootleg/bootleg-internal/tutorial_data/models/bootleg_wiki/bootleg_model.pt starting from checkpoint epoch 1 and step 0.\n",
      "2020-12-18 00:36:42,431 ************************DUMPING PREDICTIONS FOR test_natural_questions_50_bootleg.jsonl************************\n",
      "2020-12-18 00:36:42,506 64 samples, 4 batches, 49 len dataset\n",
      "2020-12-18 00:36:47,073 Writing predictions to /dfs/scratch0/lorr1/bootleg/bootleg-internal/tutorial_data/results/20200914_104853/test_natural_questions_50_bootleg/eval/bootleg_model/bootleg_labels.jsonl...\n",
      "2020-12-18 00:36:47,076 Total number of mentions across all sentences: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading values for marisa trie: 100%|██████████| 50/50 [00:00<00:00, 169672.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-18 00:36:47,107 Merging sentences together with 2 processes. Starting pool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 25/25 [00:00<00:00, 5221.47it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 47.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-18 00:36:47,906 Time to merge sub-sentences 0.5228734016418457s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading values for marisa trie: 100%|██████████| 73/73 [00:00<00:00, 182469.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-18 00:36:48,178 Starting to write files with 2 processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing data: 100%|██████████| 25/25 [00:00<00:00, 8037.53it/s]\n",
      "Writing data: 100%|██████████| 25/25 [00:00<00:00, 10172.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-18 00:37:56,478 Time to write files 68.30824828147888s\n",
      "2020-12-18 00:37:57,040 Saving contextual entity embeddings to /dfs/scratch0/lorr1/bootleg/bootleg-internal/tutorial_data/results/20200914_104853/test_natural_questions_50_bootleg/eval/bootleg_model/bootleg_embs.npy\n",
      "2020-12-18 00:37:57,041 Wrote predictions to /dfs/scratch0/lorr1/bootleg/bootleg-internal/tutorial_data/results/20200914_104853/test_natural_questions_50_bootleg/eval/bootleg_model/bootleg_labels.jsonl\n"
     ]
    }
   ],
   "source": [
    "bootleg_label_file, bootleg_emb_file = run.model_eval(args=config_args, mode=\"dump_embs\", logger=logger, is_writer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now evaluate the overall quality of the end-to-end pipeline via precision / recall metrics, where the *recall* indicates what proportion of the hand-labelled mentions Bootleg correctly detects and disambiguates, and *precision* indicates what proportion of the mentions that Bootleg labels are correct. For instance, if Bootleg only labelled the few mentions it was very confident in, then it would have a low recall and high precision.\n",
    "\n",
    "To detect if mentions match the hand-labelled mention spans, we allow for +1/-1 word in the left span boundaries (e.g., 'the wizard of oz' and 'wizard of oz' are counted as the same mention). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.68 (53/78)\n",
      "Precision: 0.73 (53/73)\n",
      "F1: 0.7\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import compute_precision_and_recall\n",
    "\n",
    "bootleg_errors = compute_precision_and_recall(orig_label_file=nq_sample_orig, \n",
    "                                              new_label_file=bootleg_label_file, \n",
    "                                              threshold=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We analyze three classes of errors in the end-to-end pipeline below: \n",
    "1. *Missing mentions*: Fail to extract the mention \n",
    "2. *Wrong entity*: Correctly extract the mention but disambiguate to the wrong candidate  \n",
    "3. *Extra mentions*: Label a mention that is not hand-labelled as a mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_idx</th>\n",
       "      <th>sentence</th>\n",
       "      <th>gold_aliases</th>\n",
       "      <th>gold_qids</th>\n",
       "      <th>gold_spans</th>\n",
       "      <th>pred_aliases</th>\n",
       "      <th>pred_spans</th>\n",
       "      <th>pred_qids</th>\n",
       "      <th>pred_probs</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>the nashville sound brought a polished and cosmopolitan sound to country music by</td>\n",
       "      <td>[nashville sound, country music]</td>\n",
       "      <td>[Q1751782, Q83440]</td>\n",
       "      <td>[[1, 3], [10, 12]]</td>\n",
       "      <td>[the nashville sound, cosmopolitan]</td>\n",
       "      <td>[[0, 3], [7, 8]]</td>\n",
       "      <td>[Q30645502, Q190656]</td>\n",
       "      <td>[1.0, 0.836]</td>\n",
       "      <td>country music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>hitchhiker 's guide to the galaxy slartibartfast quotes</td>\n",
       "      <td>[hitchhiker 's guide to the galaxy, slartibartfast]</td>\n",
       "      <td>[Q25169, Q779920]</td>\n",
       "      <td>[[0, 6], [6, 7]]</td>\n",
       "      <td>[hitchhikers guide to the galaxy]</td>\n",
       "      <td>[[0, 6]]</td>\n",
       "      <td>[Q25169]</td>\n",
       "      <td>[0.55]</td>\n",
       "      <td>slartibartfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>where did britain create colonies for its empire</td>\n",
       "      <td>[britain, empire]</td>\n",
       "      <td>[Q161885, Q8680]</td>\n",
       "      <td>[[2, 3], [7, 8]]</td>\n",
       "      <td>[its empire]</td>\n",
       "      <td>[[6, 8]]</td>\n",
       "      <td>[Q200464]</td>\n",
       "      <td>[0.539]</td>\n",
       "      <td>britain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>1970 world cup semi final italy vs germany</td>\n",
       "      <td>[1970 world cup, italy, germany]</td>\n",
       "      <td>[Q132664, Q676899, Q43310]</td>\n",
       "      <td>[[0, 3], [5, 6], [7, 8]]</td>\n",
       "      <td>[1970 world cup, germany]</td>\n",
       "      <td>[[0, 3], [7, 8]]</td>\n",
       "      <td>[Q132664, Q43310]</td>\n",
       "      <td>[0.967, 0.812]</td>\n",
       "      <td>italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>where is israel located on the world map</td>\n",
       "      <td>[israel, world map]</td>\n",
       "      <td>[Q801, Q653848]</td>\n",
       "      <td>[[2, 3], [6, 8]]</td>\n",
       "      <td>[israel]</td>\n",
       "      <td>[[2, 3]]</td>\n",
       "      <td>[Q155321]</td>\n",
       "      <td>[0.219]</td>\n",
       "      <td>world map</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>what is the t rex name in land before time</td>\n",
       "      <td>[t rex, land before time]</td>\n",
       "      <td>[Q14332, Q192403]</td>\n",
       "      <td>[[3, 5], [7, 10]]</td>\n",
       "      <td>[t rex]</td>\n",
       "      <td>[[3, 5]]</td>\n",
       "      <td>[Q14332]</td>\n",
       "      <td>[0.964]</td>\n",
       "      <td>land before time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35</td>\n",
       "      <td>reasons why south africa should include renewable energy in its energy mix</td>\n",
       "      <td>[south africa, renewable energy]</td>\n",
       "      <td>[Q258, Q12705]</td>\n",
       "      <td>[[2, 4], [6, 8]]</td>\n",
       "      <td>[south africa, energy mix]</td>\n",
       "      <td>[[2, 4], [10, 12]]</td>\n",
       "      <td>[Q258, Q1341346]</td>\n",
       "      <td>[0.686, 1.0]</td>\n",
       "      <td>renewable energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42</td>\n",
       "      <td>who proposed the coordinate system to describe the position of a point in a plane accurately</td>\n",
       "      <td>[coordinate system]</td>\n",
       "      <td>[Q62912]</td>\n",
       "      <td>[[3, 5]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>coordinate system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>43</td>\n",
       "      <td>when was last time england were in a world cup semi final</td>\n",
       "      <td>[england, world cup]</td>\n",
       "      <td>[Q47762, Q19317]</td>\n",
       "      <td>[[4, 5], [8, 10]]</td>\n",
       "      <td>[england]</td>\n",
       "      <td>[[4, 5]]</td>\n",
       "      <td>[Q47762]</td>\n",
       "      <td>[0.282]</td>\n",
       "      <td>world cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44</td>\n",
       "      <td>the representative of the british crown in nz</td>\n",
       "      <td>[british crown, nz]</td>\n",
       "      <td>[Q21941952, Q664]</td>\n",
       "      <td>[[4, 6], [7, 8]]</td>\n",
       "      <td>[british crown]</td>\n",
       "      <td>[[4, 6]]</td>\n",
       "      <td>[Q21941952]</td>\n",
       "      <td>[0.372]</td>\n",
       "      <td>nz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>48</td>\n",
       "      <td>what was the japanese motivation for bombing pearl harbor</td>\n",
       "      <td>[japanese, pearl harbor]</td>\n",
       "      <td>[Q188712, Q127091]</td>\n",
       "      <td>[[3, 4], [7, 9]]</td>\n",
       "      <td>[pearl harbor]</td>\n",
       "      <td>[[7, 9]]</td>\n",
       "      <td>[Q52418]</td>\n",
       "      <td>[0.669]</td>\n",
       "      <td>japanese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sent_idx  \\\n",
       "0          2   \n",
       "1         11   \n",
       "2         16   \n",
       "3         18   \n",
       "4         23   \n",
       "5         30   \n",
       "6         35   \n",
       "7         42   \n",
       "8         43   \n",
       "9         44   \n",
       "10        48   \n",
       "\n",
       "                                                                                        sentence  \\\n",
       "0              the nashville sound brought a polished and cosmopolitan sound to country music by   \n",
       "1                                        hitchhiker 's guide to the galaxy slartibartfast quotes   \n",
       "2                                               where did britain create colonies for its empire   \n",
       "3                                                     1970 world cup semi final italy vs germany   \n",
       "4                                                       where is israel located on the world map   \n",
       "5                                                     what is the t rex name in land before time   \n",
       "6                     reasons why south africa should include renewable energy in its energy mix   \n",
       "7   who proposed the coordinate system to describe the position of a point in a plane accurately   \n",
       "8                                      when was last time england were in a world cup semi final   \n",
       "9                                                  the representative of the british crown in nz   \n",
       "10                                     what was the japanese motivation for bombing pearl harbor   \n",
       "\n",
       "                                           gold_aliases  \\\n",
       "0                      [nashville sound, country music]   \n",
       "1   [hitchhiker 's guide to the galaxy, slartibartfast]   \n",
       "2                                     [britain, empire]   \n",
       "3                      [1970 world cup, italy, germany]   \n",
       "4                                   [israel, world map]   \n",
       "5                             [t rex, land before time]   \n",
       "6                      [south africa, renewable energy]   \n",
       "7                                   [coordinate system]   \n",
       "8                                  [england, world cup]   \n",
       "9                                   [british crown, nz]   \n",
       "10                             [japanese, pearl harbor]   \n",
       "\n",
       "                     gold_qids                gold_spans  \\\n",
       "0           [Q1751782, Q83440]        [[1, 3], [10, 12]]   \n",
       "1            [Q25169, Q779920]          [[0, 6], [6, 7]]   \n",
       "2             [Q161885, Q8680]          [[2, 3], [7, 8]]   \n",
       "3   [Q132664, Q676899, Q43310]  [[0, 3], [5, 6], [7, 8]]   \n",
       "4              [Q801, Q653848]          [[2, 3], [6, 8]]   \n",
       "5            [Q14332, Q192403]         [[3, 5], [7, 10]]   \n",
       "6               [Q258, Q12705]          [[2, 4], [6, 8]]   \n",
       "7                     [Q62912]                  [[3, 5]]   \n",
       "8             [Q47762, Q19317]         [[4, 5], [8, 10]]   \n",
       "9            [Q21941952, Q664]          [[4, 6], [7, 8]]   \n",
       "10          [Q188712, Q127091]          [[3, 4], [7, 9]]   \n",
       "\n",
       "                           pred_aliases          pred_spans  \\\n",
       "0   [the nashville sound, cosmopolitan]    [[0, 3], [7, 8]]   \n",
       "1     [hitchhikers guide to the galaxy]            [[0, 6]]   \n",
       "2                          [its empire]            [[6, 8]]   \n",
       "3             [1970 world cup, germany]    [[0, 3], [7, 8]]   \n",
       "4                              [israel]            [[2, 3]]   \n",
       "5                               [t rex]            [[3, 5]]   \n",
       "6            [south africa, energy mix]  [[2, 4], [10, 12]]   \n",
       "7                                    []                  []   \n",
       "8                             [england]            [[4, 5]]   \n",
       "9                       [british crown]            [[4, 6]]   \n",
       "10                       [pearl harbor]            [[7, 9]]   \n",
       "\n",
       "               pred_qids      pred_probs              error  \n",
       "0   [Q30645502, Q190656]    [1.0, 0.836]      country music  \n",
       "1               [Q25169]          [0.55]     slartibartfast  \n",
       "2              [Q200464]         [0.539]            britain  \n",
       "3      [Q132664, Q43310]  [0.967, 0.812]              italy  \n",
       "4              [Q155321]         [0.219]          world map  \n",
       "5               [Q14332]         [0.964]   land before time  \n",
       "6       [Q258, Q1341346]    [0.686, 1.0]   renewable energy  \n",
       "7                     []              []  coordinate system  \n",
       "8               [Q47762]         [0.282]          world cup  \n",
       "9            [Q21941952]         [0.372]                 nz  \n",
       "10              [Q52418]         [0.669]           japanese  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bootleg_errors['missing_mention'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mentions were discarded due to not being in our candidate map or being filtered out during mention extractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_idx</th>\n",
       "      <th>sentence</th>\n",
       "      <th>gold_aliases</th>\n",
       "      <th>gold_qids</th>\n",
       "      <th>gold_spans</th>\n",
       "      <th>pred_aliases</th>\n",
       "      <th>pred_spans</th>\n",
       "      <th>pred_qids</th>\n",
       "      <th>pred_probs</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25</td>\n",
       "      <td>which of these was not an export of ancient greece</td>\n",
       "      <td>[ancient greece]</td>\n",
       "      <td>[Q11772]</td>\n",
       "      <td>[[8, 10]]</td>\n",
       "      <td>[ancient greece]</td>\n",
       "      <td>[[8, 10]]</td>\n",
       "      <td>[Q1294184]</td>\n",
       "      <td>[0.394]</td>\n",
       "      <td>ancient greece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "      <td>who plays claire underwood 's mom on house of cards</td>\n",
       "      <td>[claire underwood, house of cards]</td>\n",
       "      <td>[Q14915624, Q3330940]</td>\n",
       "      <td>[[2, 4], [7, 10]]</td>\n",
       "      <td>[claire underwood, house of cards]</td>\n",
       "      <td>[[2, 4], [7, 10]]</td>\n",
       "      <td>[Q14915624, Q578361]</td>\n",
       "      <td>[1.0, 0.556]</td>\n",
       "      <td>house of cards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40</td>\n",
       "      <td>where does the last name vigil come from</td>\n",
       "      <td>[vigil]</td>\n",
       "      <td>[Q16878937]</td>\n",
       "      <td>[[5, 6]]</td>\n",
       "      <td>[vigil]</td>\n",
       "      <td>[[5, 6]]</td>\n",
       "      <td>[Q1238731]</td>\n",
       "      <td>[0.672]</td>\n",
       "      <td>vigil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>who did the voice of the magician in frosty the snowman</td>\n",
       "      <td>[frosty the snowman]</td>\n",
       "      <td>[Q5506238]</td>\n",
       "      <td>[[8, 11]]</td>\n",
       "      <td>[magician, frosty the snowman]</td>\n",
       "      <td>[[6, 7], [8, 11]]</td>\n",
       "      <td>[Q148442, Q2569914]</td>\n",
       "      <td>[0.701, 0.949]</td>\n",
       "      <td>frosty the snowman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>the nashville sound brought a polished and cosmopolitan sound to country music by</td>\n",
       "      <td>[nashville sound, country music]</td>\n",
       "      <td>[Q1751782, Q83440]</td>\n",
       "      <td>[[1, 3], [10, 12]]</td>\n",
       "      <td>[the nashville sound, cosmopolitan]</td>\n",
       "      <td>[[0, 3], [7, 8]]</td>\n",
       "      <td>[Q30645502, Q190656]</td>\n",
       "      <td>[1.0, 0.836]</td>\n",
       "      <td>nashville sound</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sent_idx  \\\n",
       "6         25   \n",
       "7         29   \n",
       "10        40   \n",
       "0          0   \n",
       "1          2   \n",
       "\n",
       "                                                                             sentence  \\\n",
       "6                                  which of these was not an export of ancient greece   \n",
       "7                                 who plays claire underwood 's mom on house of cards   \n",
       "10                                           where does the last name vigil come from   \n",
       "0                             who did the voice of the magician in frosty the snowman   \n",
       "1   the nashville sound brought a polished and cosmopolitan sound to country music by   \n",
       "\n",
       "                          gold_aliases              gold_qids  \\\n",
       "6                     [ancient greece]               [Q11772]   \n",
       "7   [claire underwood, house of cards]  [Q14915624, Q3330940]   \n",
       "10                             [vigil]            [Q16878937]   \n",
       "0                 [frosty the snowman]             [Q5506238]   \n",
       "1     [nashville sound, country music]     [Q1751782, Q83440]   \n",
       "\n",
       "            gold_spans                         pred_aliases  \\\n",
       "6            [[8, 10]]                     [ancient greece]   \n",
       "7    [[2, 4], [7, 10]]   [claire underwood, house of cards]   \n",
       "10            [[5, 6]]                              [vigil]   \n",
       "0            [[8, 11]]       [magician, frosty the snowman]   \n",
       "1   [[1, 3], [10, 12]]  [the nashville sound, cosmopolitan]   \n",
       "\n",
       "           pred_spans             pred_qids      pred_probs  \\\n",
       "6           [[8, 10]]            [Q1294184]         [0.394]   \n",
       "7   [[2, 4], [7, 10]]  [Q14915624, Q578361]    [1.0, 0.556]   \n",
       "10           [[5, 6]]            [Q1238731]         [0.672]   \n",
       "0   [[6, 7], [8, 11]]   [Q148442, Q2569914]  [0.701, 0.949]   \n",
       "1    [[0, 3], [7, 8]]  [Q30645502, Q190656]    [1.0, 0.836]   \n",
       "\n",
       "                 error  \n",
       "6       ancient greece  \n",
       "7       house of cards  \n",
       "10               vigil  \n",
       "0   frosty the snowman  \n",
       "1      nashville sound  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bootleg_errors['wrong_entity']).sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the errors Bootleg makes is predicting too general of a candidate (e.g. house of cards -- structure made of playing cards -- instead of the political drama). Other errors are due to ambiguous sentences. Finally another bucket of errors suggests that we need to boost certain training signals -- this is an area we're actively pursuing in Bootleg with an investigation of model guidability!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_idx</th>\n",
       "      <th>sentence</th>\n",
       "      <th>gold_aliases</th>\n",
       "      <th>gold_qids</th>\n",
       "      <th>gold_spans</th>\n",
       "      <th>pred_aliases</th>\n",
       "      <th>pred_spans</th>\n",
       "      <th>pred_qids</th>\n",
       "      <th>pred_probs</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>who played smiley in tinker tailor soldier spy</td>\n",
       "      <td>[tinker tailor soldier spy]</td>\n",
       "      <td>[Q681962]</td>\n",
       "      <td>[[4, 8]]</td>\n",
       "      <td>[smiley, tinker tailor soldier spy]</td>\n",
       "      <td>[[2, 3], [4, 8]]</td>\n",
       "      <td>[Q11241, Q582811]</td>\n",
       "      <td>[0.324, 0.532]</td>\n",
       "      <td>smiley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>who did the voice of the magician in frosty the snowman</td>\n",
       "      <td>[frosty the snowman]</td>\n",
       "      <td>[Q5506238]</td>\n",
       "      <td>[[8, 11]]</td>\n",
       "      <td>[magician, frosty the snowman]</td>\n",
       "      <td>[[6, 7], [8, 11]]</td>\n",
       "      <td>[Q148442, Q2569914]</td>\n",
       "      <td>[0.701, 0.949]</td>\n",
       "      <td>magician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>i see the river tiber foaming with much blood</td>\n",
       "      <td>[river tiber]</td>\n",
       "      <td>[Q13712]</td>\n",
       "      <td>[[3, 5]]</td>\n",
       "      <td>[river tiber, foaming]</td>\n",
       "      <td>[[3, 5], [5, 6]]</td>\n",
       "      <td>[Q13712, Q7243541]</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>foaming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>once upon a time season 6 episode list</td>\n",
       "      <td>[once upon a time season 6]</td>\n",
       "      <td>[Q23301616]</td>\n",
       "      <td>[[0, 6]]</td>\n",
       "      <td>[once upon a time season 6, episode list]</td>\n",
       "      <td>[[0, 6], [6, 8]]</td>\n",
       "      <td>[Q23301616, Q7537343]</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>episode list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>the nashville sound brought a polished and cosmopolitan sound to country music by</td>\n",
       "      <td>[nashville sound, country music]</td>\n",
       "      <td>[Q1751782, Q83440]</td>\n",
       "      <td>[[1, 3], [10, 12]]</td>\n",
       "      <td>[the nashville sound, cosmopolitan]</td>\n",
       "      <td>[[0, 3], [7, 8]]</td>\n",
       "      <td>[Q30645502, Q190656]</td>\n",
       "      <td>[1.0, 0.836]</td>\n",
       "      <td>cosmopolitan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_idx  \\\n",
       "3        24   \n",
       "0         0   \n",
       "4        27   \n",
       "2         8   \n",
       "1         2   \n",
       "\n",
       "                                                                            sentence  \\\n",
       "3                                     who played smiley in tinker tailor soldier spy   \n",
       "0                            who did the voice of the magician in frosty the snowman   \n",
       "4                                      i see the river tiber foaming with much blood   \n",
       "2                                             once upon a time season 6 episode list   \n",
       "1  the nashville sound brought a polished and cosmopolitan sound to country music by   \n",
       "\n",
       "                       gold_aliases           gold_qids          gold_spans  \\\n",
       "3       [tinker tailor soldier spy]           [Q681962]            [[4, 8]]   \n",
       "0              [frosty the snowman]          [Q5506238]           [[8, 11]]   \n",
       "4                     [river tiber]            [Q13712]            [[3, 5]]   \n",
       "2       [once upon a time season 6]         [Q23301616]            [[0, 6]]   \n",
       "1  [nashville sound, country music]  [Q1751782, Q83440]  [[1, 3], [10, 12]]   \n",
       "\n",
       "                                pred_aliases         pred_spans  \\\n",
       "3        [smiley, tinker tailor soldier spy]   [[2, 3], [4, 8]]   \n",
       "0             [magician, frosty the snowman]  [[6, 7], [8, 11]]   \n",
       "4                     [river tiber, foaming]   [[3, 5], [5, 6]]   \n",
       "2  [once upon a time season 6, episode list]   [[0, 6], [6, 8]]   \n",
       "1        [the nashville sound, cosmopolitan]   [[0, 3], [7, 8]]   \n",
       "\n",
       "               pred_qids      pred_probs         error  \n",
       "3      [Q11241, Q582811]  [0.324, 0.532]        smiley  \n",
       "0    [Q148442, Q2569914]  [0.701, 0.949]      magician  \n",
       "4     [Q13712, Q7243541]      [1.0, 1.0]       foaming  \n",
       "2  [Q23301616, Q7537343]      [1.0, 1.0]  episode list  \n",
       "1   [Q30645502, Q190656]    [1.0, 0.836]  cosmopolitan  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bootleg_errors['extra_mention']).sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that Bootleg may detect and label extraneous mentions that were not hand-labelled. Setting the threshold higher helps to reduce these predictions, as does using a 'NC' candidate for training, which Bootleg also supports. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare to TAGME \n",
    "\n",
    "To get a sense of how Bootleg is doing compared to other systems, we evaluate [TAGME](https://arxiv.org/pdf/1006.3498.pdf), an existing tool to extract and disambiguate mentions. To run TAGME, you need to get a (free) authorization token. Instructions for obtaining a token are [here](https://sobigdata.d4science.org/web/tagme/tagme-help). You will need to verify your account and then follow the \"access the VRE\") link. We've also provided the file with TAGME labels for a given threshold for download if you want to skip the authorization token.\n",
    "\n",
    "We note that unlike TAGME, Bootleg also outputs contextual entity embeddings which can be loaded for use in downstream tasks (e.g. relation extraction, question answering). Check out the Entity Embedding tutorial for more details! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tagme\n",
    "# Set the authorization token for subsequent calls.\n",
    "tagme.GCUBE_TOKEN = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagme_label_file = f'{root_dir}/data/nq/test_natural_questions_50_tagme.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not have a token, skip the cell below and load the pre-generated TAGME labels. If you do have a token, you can play with changing the threshold below and see how it affects the results. Increasing the threshold increases the precision but decreases the recall as TAGME, as TAGME will label fewer mentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a mapping from Wikipedia pageids to Wikidata QIDs to get the QIDs predicted by TAGME \n",
    "wpid2qid = ujson.load(open(f'{root_dir}/data/wiki_entity_data/entity_mappings/wpid2qid.json'))\n",
    "\n",
    "# As the threshold increases, the precision increases, but the recall decreases\n",
    "tagme_annotate(in_file=nq_sample_orig, out_file=tagme_label_file, threshold=0.3, wpid2qid=wpid2qid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.63 (49/78)\n",
      "Precision: 0.58 (49/84)\n",
      "F1: 0.6\n"
     ]
    }
   ],
   "source": [
    "from utils import compute_precision_and_recall\n",
    "tagme_errors = compute_precision_and_recall(orig_label_file=nq_sample_orig, \n",
    "                                            new_label_file=tagme_label_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that TAGME has worse recall and precision than Bootleg. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Annotate On-the-Fly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To annotate individual sentences with Bootleg, we  also support annotate-on-the-fly mode. \n",
    "\n",
    "**Note that Annotator is not optimized and is only intended to be used for quick experimentation and for demos. We recommend using the above pipeline (`extract_mentions` and `model_eval` functions) for evaluating datasets. These functions leverage multiprocessing, caching of preprocessed data, and batching to speed up evaluation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we create an annotator object. This loads the model and entity databases. We use the `config_args` loaded from the previous step. Note it takes several minutes for the initial load of the model and the entity data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "2020-12-18 00:38:42,703 Reading entity database\n",
      "2020-12-18 00:39:46,212 Reading word tokenizers\n",
      "2020-12-18 00:39:46,279 Loading model\n",
      "2020-12-18 00:40:02,269 Loading embeddings...\n",
      "2020-12-18 00:40:26,525 Finished loading embeddings.\n",
      "2020-12-18 00:40:27,087 Loading candidate map\n",
      "2020-12-18 00:40:49,061 Loading candidate mapping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8002525/8002525 [00:18<00:00, 443699.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-18 00:41:07,100 Loaded candidate mapping with 8002525 aliases.\n",
      "2020-12-18 00:41:20,004 Reading in alias table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from bootleg.annotator import Annotator\n",
    "\n",
    "ann = Annotator(config_args=config_args, cand_map=cand_map, device='cuda' if not use_cpu else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to TAGME, we allow setting a threshold to only return mentions with labels greater than some probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.set_threshold(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in sentences to see what Bootleg predicts! For each mention, Bootleg outputs\n",
    "- QIDs (or \"NC\" for \"No Candidate\")\n",
    "- probabilities\n",
    "- QID title\n",
    "- mention candidates\n",
    "- mention candidate probabilities\n",
    "- spans of mentions\n",
    "- mentions\n",
    "\n",
    "The QIDs map to Wikidata -- to look them up you can use https://www.wikidata.org/wiki/Q1454 and replace the QID. \"NC\" means Bootleg did not find a good match among the candidates in the candidate list given the context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prepping data: 100%|██████████| 1/1 [00:00<00:00, 28.88it/s]\n",
      "Evaluating model: 100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([['Q1517373', 'Q1454']],\n",
       " [[1.0, 0.9986315369606018]],\n",
       " [['Outer Banks', 'North Carolina']])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.label_mentions(\"where is the outer banks in north carolina\")[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prepping data: 100%|██████████| 1/1 [00:00<00:00, 48.84it/s]\n",
      "Evaluating model: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([['Q487330']], [[0.8821306228637695]], [['Fiddler on the Roof']])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.label_mentions(\"cast of characters in fiddler on the roof\")[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the entity disambiguation problem can be quite tricky -- in the above example we predict the song \"Fiddler on the Roof\" the music instead of the hand-label of the movie (https://www.wikidata.org/wiki/Q934036). Giving additional cues may help though -- for instance, if we add \"the movie\", the prediction changes to the movie! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prepping data: 100%|██████████| 1/1 [00:00<00:00, 35.71it/s]\n",
      "Evaluating model: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([['Q934036']], [[0.7687084674835205]], [['Fiddler on the Roof (film)']])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.label_mentions(\"cast of characters in the movie fiddler on the roof\")[:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}